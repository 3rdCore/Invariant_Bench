{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cd1b81",
   "metadata": {},
   "source": [
    "# Contrastive Learning Experiment Notebook\n",
    "\n",
    "Train algorithms on increasing dataset sizes and plot risk/likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf6cf4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Environment, imports, device selection, and reproducibility seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b518c902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/t/tom.marty/invariant_bench/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using seed: 0\n"
     ]
    }
   ],
   "source": [
    "# Imports and path setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Add project root to path if needed (before importing project modules)\n",
    "sys.path.append(str(Path('..').resolve()))\n",
    "\n",
    "from source.dataset import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "from source.utils import hparams_registry\n",
    "\n",
    "# Select device: use GPU if available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "# Reproducibility\n",
    "seed = int(os.environ.get('SEED', 0))\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "print(f'Using seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d669f4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions for robust error handling loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from source.utils.misc import group_counts, build_group_index, w, safe_mean, InfiniteDataLoader, find_timestamp_root\n",
    "print(\"Utility functions for robust error handling loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad476be2",
   "metadata": {},
   "source": [
    "## Experiment configuration\n",
    "\n",
    "Dataset choice, learners, and result containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195cc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "  Dataset: CMNIST\n",
      "  Data path: /home/mila/t/tom.marty/scratch/invariant_bench/data/benchmark\n",
      "  Stratified sampling: True\n",
      "  Debug mode: False\n"
     ]
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "# Experiment config\n",
    "DATA_PATH = os.path.expanduser('~/scratch/invariant_bench/data/benchmark')\n",
    "\n",
    "DATASET_NAME = 'CMNIST'\n",
    "NETWORK_NAME = 'mnist_cnn'  # 'resnet', 'simple_mlp', or 'mnist_cnn'\n",
    "BATCH_SIZE = 128\n",
    "NUM_FIT = 7 # number of points in the PCL curve\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "USE_STRATIFIED = True # Toggle: use stratified (label, attr) sampling such that the class ratio is preserved\n",
    "ROBUST_TRAINING = True  # Enable     robust error handling\n",
    "MAX_RETRIES = 3  # Maximum number of retries for failed operations\n",
    "CONTINUE_ON_ERROR = True  # Continue with next algorithm/size if current fails\n",
    "SAVE_PARTIAL_RESULTS = True  # Save results even if some experiments fail\n",
    "\n",
    "# Early stopping configuration\n",
    "ES_MIN_DELTA = 0\n",
    "ES_PATIENCE = 3         # checkpoints without improvement before stopping\n",
    "\n",
    "\n",
    "print('Config:')\n",
    "print(f'  Dataset: {DATASET_NAME}')\n",
    "print(f'  Data path: {DATA_PATH}')\n",
    "print(f'  Stratified sampling: {USE_STRATIFIED}')\n",
    "print(f'  Debug mode: {DEBUG}')\n",
    "\n",
    "# Prepare per-learner results storage\n",
    "val_loss_map = []           # validation loss means (best)\n",
    "train_loss_map = []         # training loss mean (per size)\n",
    "test_loss_map  = []         # test loss means (final model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d32c5c",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Defaults and dataset-specific overrides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ebcc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters template\n",
    "import os\n",
    "from source.utils.misc import safe_float_env\n",
    "\n",
    "# We'll derive specific hparams per learner in the training loop\n",
    "base_hparams = hparams_registry.default_hparams('ERM', DATASET_NAME)\n",
    "base_hparams['image_arch'] = NETWORK_NAME\n",
    "\n",
    "if NETWORK_NAME == 'resnet':\n",
    "    base_hparams.update({\n",
    "        'pretrained': False,\n",
    "        'input_size': 224\n",
    "    })\n",
    "elif NETWORK_NAME == 'simple_mlp' or NETWORK_NAME == 'mnist_cnn':\n",
    "    base_hparams.update({\n",
    "        'input_size': 28, \n",
    "        'lr': 1e-3,\n",
    "    })\n",
    "\n",
    "\n",
    "#TODO check that pretrained=FALSE for ResNet works\n",
    "\"\"\"\n",
    "Colored MNIST specific hyperparameters:\n",
    "- cmnist_label_prob: Probability of label imbalance (default 0.5)\n",
    "- cmnist_attr_prob: Probability of attribute imbalance (default 0.5)\n",
    "- cmnist_spur_prob: Controls the summed diagonal proportion (0,1). The more this is towards 0, the more the color is spuriously correlated with the label. \n",
    "\"\"\"\n",
    "\n",
    "cmnist_label_prob = safe_float_env(\"CMNIST_LABEL_PROB\", 0.5)\n",
    "cmnist_attr_prob = safe_float_env(\"CMNIST_ATTR_PROB\", 0.5)\n",
    "cmnist_spur_prob = safe_float_env(\"CMNIST_SPUR_PROB\", 0.1)\n",
    "\n",
    "if DATASET_NAME == 'CMNIST':\n",
    "    base_hparams.update({\n",
    "        'cmnist_label_prob': cmnist_label_prob,\n",
    "        'cmnist_attr_prob': cmnist_attr_prob, \n",
    "        'cmnist_spur_prob': cmnist_spur_prob,\n",
    "        'cmnist_flip_prob': 0.0,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85799a7a",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Load train/val/test splits and preview samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa12b7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train size: 30000 | Val size: 10000 | Test size: 20000 (restricted)\n",
      "  Input shape: (3, 28, 28) | data_type: images\n",
      "  num_labels: 2 | num_attributes: 2\n",
      "Stratified groups (counts): {(0, 0): 13849, (0, 1): 1482, (1, 0): 1480, (1, 1): 13189}\n",
      "\n",
      "Class distribution:\n",
      "       count  percentage\n",
      "class                   \n",
      "0      15331        51.1\n",
      "1      14669        48.9\n",
      "\n",
      "Attribute distribution:\n",
      "           count  percentage\n",
      "attribute                   \n",
      "0          15329        51.1\n",
      "1          14671        48.9\n",
      "\n",
      "Group (class, attribute) distribution:\n",
      "                 count  percentage\n",
      "class attribute                   \n",
      "0     0          13849       46.16\n",
      "      1           1482        4.94\n",
      "1     0           1480        4.93\n",
      "      1          13189       43.96\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwgAAAMVCAYAAADTTdNSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfc5JREFUeJzt3Xt81NWd//H3iJjECHIpQUUBKVhRsVhArOUSUKEKKlVEqauAXdZ6qS4rUMVVQNtYi1yqQrW6gmKUFQRq0e22NYC/LSyXVqnchCBsgQKCCgZEFDm/P1qO5DMnmclkZpKZvJ6PB3+8z3y/53sGPnzJ4TtnTsQ55wQAAAAAko6r6QEAAAAAqD2YIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8GpsgrBlyxZFIhE99thjSetz0aJFikQiWrRoUdL6RPag5pBu1BzSjZpDOlFv2atKE4QZM2YoEolo5cqVqRpPjXrvvfc0YsQIXXzxxcrNzVUkEtGWLVuS1v+0adMUiUTUtWvX4Otr167VuHHjgtecNm2aZsyYkbSxWKl+74nK9pqTpO3bt2vQoEFq1KiRGjZsqKuvvlrvv/9+UvoePXq0IpGIrr/++uDrS5Ys0bhx47R3796o14qKijR//vykjKMi69at03e/+12ddNJJatKkiW666Sbt3r07pdeMhZqrHmqu6qi56qHmqibb642f5ZLz3vmI0TGWLl2qxx9/XGVlZWrfvn3S+y8uLlbr1q21fPlylZaWRr2+du1ajR8/vkaKKtXvHWH79+9Xr169tHjxYo0ZM0bjx4/X22+/rZ49e+rDDz+sVt/OOb388stq3bq1fvOb36isrCzqmCVLlmj8+PE18g/ntm3b1KNHD5WWlqqoqEgjR47U66+/rssuu0yff/55yq5b11Fz1Fy6UXPUXDrxs1xy3jsThGNcddVV2rt3r959913deOONSe178+bNWrJkiSZNmqRmzZqpuLg4qf0f68CBA1U+J5XvHRWbNm2aNm7cqAULFmj06NEaMWKEfve732nHjh2aOHFitfpetGiRtm3bpueee06HDx/W3LlzkzTqaInUXFFRkQ4cOKCSkhLdddddGjNmjF555RWtWrUqpTfQuo6ao+bSjZqj5tKJn+WS896TPkH4/PPP9eCDD6pTp046+eSTlZ+fr+7du2vhwoUVnjN58mS1atVKeXl56tmzp1avXh11zPr16zVw4EA1adJEubm56ty5s1577bWY4/n000+1fv167dmzJ+axTZo0UYMGDWIel4ji4mI1btxY/fr108CBA6OKasaMGbruuuskSb169VIkEvGfwWvdurXWrFmjxYsX+/bCwkJ/XiQS0eLFi3X77beroKBAp59+uqTa895TLZNrbs6cOerSpYu6dOni284++2xdcskleuWVV2KeX5ni4mKdc8456tWrly699NKomhs3bpxGjRolSTrzzDN9bR39TOmBAwf0/PPP+/ahQ4f68yKRiNauXavvf//7aty4sbp16yZJ2rdvn9avX699+/bFHN+rr76q/v37q2XLlr7t0ksv1VlnnVXt955q1FwYNZc61FwYNZcamVxv/CyXnPee9AnCJ598omeffVaFhYV69NFHNW7cOO3evVt9+/bVO++8E3X8Cy+8oMcff1x33HGH7rvvPq1evVq9e/fWrl27/DFr1qzRRRddpHXr1unee+/VxIkTlZ+frwEDBmjevHmVjmf58uVq3769nnzyyWS/1SopLi7WNddcoxNOOEGDBw/Wxo0btWLFCv96jx49dNddd0mSxowZo5kzZ2rmzJlq3769pkyZotNPP11nn322b7///vvL9X/77bdr7dq1evDBB3XvvfdKqj3vPdUyteaOHDmiv/zlL+rcuXPUaxdeeKE2bdoUfFwej0OHDunVV1/V4MGDJUmDBw9WSUmJdu7c6Y+55ppr/OuTJ0/2tdWsWTPNnDlTOTk56t69u2+/9dZby13juuuu06effqqioiINHz5ckjRv3jy1b98+5u/R9u3b9cEHH1T43t9+++2E3ne6UHPRqLnUouaiUXOpk6n1lmp16mc5VwXTp093ktyKFSsqPObw4cPu0KFD5do+/vhj17x5c3fLLbf4ts2bNztJLi8vz23bts23L1u2zElyI0aM8G2XXHKJ69Chg/vss89825EjR9zFF1/s2rVr59sWLlzoJLmFCxdGtY0dO7Yqb9VNmDDBSXKbN2+u0nkhK1eudJLc73//ez/2008/3d19993ljps9e3bU+I8699xzXc+ePaPaj/6ZdOvWzR0+fLjca7XhvVdXNtfc7t27nST30EMPRb02depUJ8mtX7++0j4qMmfOHCfJbdy40Tnn3CeffOJyc3Pd5MmTyx1X2Z91fn6+GzJkSFT72LFjnSQ3ePDgqNeO/nlNnz690vGtWLHCSXIvvPBC1GujRo1yksr93qcTNUfNpRs1R82lUzbXm8XPcom/96Q/QahXr55OOOEESX//n4OPPvpIhw8fVufOnfXnP/856vgBAwaoRYsWPl944YXq2rWr3njjDUnSRx99pJKSEg0aNEhlZWXas2eP9uzZow8//FB9+/bVxo0btX379grHU1hYKOecxo0bl9w3WgXFxcVq3ry5evXqJUn+2xZmzZqlL7/8MinXGD58uOrVq1eurTa893TI1Jo7ePCgJCknJyfqtdzc3HLHVFVxcbE6d+6stm3bSpIaNGigfv36JfXzkj/84Q+j2oYOHSrnnH9MX5FUvvd0oOaiUXOpRc1Fo+ZSJ1PrLZXq2s9yKVmk/Pzzz+v8889Xbm6umjZtqmbNmun1118Pfl6vXbt2UW1nnXWWX/1dWloq55weeOABNWvWrNyvsWPHSpI++OCDVLyNpPjyyy81a9Ys9erVS5s3b1ZpaalKS0vVtWtX7dq1S2+++WZSrnPmmWcmpZ9MlYk1l5eXJ+nvj8mtzz77rNwxVbF371698cYb6tmzp6+30tJSfec739HKlSu1YcOG6g38H6pTc6l67+lEzX2FmksPau4r1FzqZWK9pUpd/Fnu+GR3+OKLL2ro0KEaMGCARo0apYKCAtWrV0+PPPKINm3aVOX+jhw5IkkaOXKk+vbtGzzm6P8e1EYlJSXasWOHZs2apVmzZkW9XlxcrD59+lT7OrX5JpNqmVpzTZo0UU5Ojnbs2BH12tG20047rcr9zp49W4cOHdLEiROD3xBSXFys8ePHV33ARnVq7tRTT5WkCt/70d+b2oqaK4+aSz1qrjxqLrUytd5SpS7+LJf0CcKcOXPUpk0bzZ07V5FIxLcfnSFaGzdujGrbsGGDWrduLUlq06aNJKl+/fq69NJLkz3clCsuLlZBQYGmTp0a9drcuXM1b948PfXUU8rLyyv3+2VV9lpdl6k1d9xxx6lDhw7BzWqWLVumNm3aJPRtBMXFxTrvvPOC7//pp5/WSy+95P/hrKmaa9GihZo1axZ878uXL1fHjh1Tdu1koObKo+ZSj5orj5pLrUytt1Spiz/LpWQNgvT3zUuOWrZsmZYuXRo8fv78+eU+d7Z8+XItW7ZMl19+uSSpoKBAhYWFevrpp4Oz8Fi7EVbl66GS7eDBg5o7d6769++vgQMHRv268847VVZW5r/iKz8/X5KCm7nk5+cH2ytTk+89nTK55gYOHKgVK1aU+wfkvffeU0lJif+qtKrYunWr3nrrLQ0aNChYc8OGDVNpaamWLVsmKfk1V5Wv/7v22mu1YMECbd261be9+eab2rBhQ0LvPZ2oua9Qc+lBzX2Fmku9TK63ZKurP8sl9AThueee029/+9uo9rvvvlv9+/fX3Llz9b3vfU/9+vXT5s2b9dRTT+mcc87R/v37o85p27atunXrpttuu02HDh3SlClT1LRpU40ePdofM3XqVHXr1k0dOnTQ8OHD1aZNG+3atUtLly7Vtm3btGrVqgrHunz5cvXq1Utjx46NucBj3759euKJJyRJf/zjHyVJTz75pBo1aqRGjRrpzjvv9McOHTpUzz//vDZv3uxnyNZrr72msrIyXXXVVcHXL7roIr/RxvXXX6+OHTuqXr16evTRR7Vv3z7l5OSod+/eKigoUKdOnfTLX/5SP/nJT9S2bVsVFBSod+/elb6fVL33mpCtNXf77bfrmWeeUb9+/TRy5EjVr19fkyZNUvPmzXXPPfeUO7awsFCLFy8ud8O2XnrpJTnnKqy5K664Qscff7yKi4vVtWtXderUSZJ0//3364YbblD9+vV15ZVXKj8/X506ddIf/vAHTZo0SaeddprOPPPMCreWP2revHkaNmyYpk+fHnMB35gxYzR79mz16tVLd999t/bv368JEyaoQ4cOGjZsWKXnpgM1R82lGzVHzaVTttYbP8sl6We5qnzl0dGvYaro19atW92RI0dcUVGRa9WqlcvJyXEXXHCBW7BggRsyZIhr1aqV7+voV2NNmDDBTZw40Z1xxhkuJyfHde/e3a1atSrq2ps2bXI333yzO+WUU1z9+vVdixYtXP/+/d2cOXP8MdX9aqyjYwr9Onbszjl37bXXury8PPfxxx9X2N+VV17pcnNz3YEDByo8ZujQoa5+/fpuz549zjnnnnnmGdemTRtXr169cu9l586drl+/fq5BgwZOkv+arMq+rixV7z2dsr3mnHNu69atbuDAga5hw4bupJNOcv379/df23esTp06uVNOOaXSvjp06OBatmxZ6TGFhYWuoKDAffHFF8455x5++GHXokULd9xxx5X7SrT169e7Hj16uLy8PCfJfxXg0a//2717d1Tf8X7931GrV692ffr0cSeeeKJr1KiRu/HGG93OnTvjOjdVqLmvUHPpQc19hZpLvWyvN36WS87PchHnKpmmo0LNmzfXzTffrAkTJtT0UFAHlJWVqUmTJpoyZYruuOOOmh4O6gBqDulGzSHd+FmuYin5mtNst2bNGh08eFA//vGPa3ooqCPeeusttWjRwu/kCaQaNYd0o+aQTvwsVzmeIAAAAADweIIAAAAAwGOCAAAAAMBjggAAAADAY4IAAAAAwEtoo7SjIpE2yRoHaiHn3q/pIUSh5rIbNYd0q201R71lt9pWbxI1l+0SrTmeIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwjq/pAQCI37cCbXeafLPJL5j8RKCPtxMeEQAAyDY8QQAAAADgMUEAAAAA4DFBAAAAAOCxBuGo0FTp5AT6sR8IP9Hkb5h8R6CPx0webPJngXN+ZvJDgWOQcb5p8u8DxzQ02Zl8k8lXBfr4WlUGBSRBb5OLTe4ZOGdDisaCzHa/yeMDx9h/4gtNfitpowGyA08QAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHjZsUj5jEDbCSZfbHI3kxsF+rg20QFVYpvJjweO+Z7JZSavCpyzOOERoRbpYvKrJofWzdtFybZcPje5aaCPi0z+k8lfBM5B/LqbHPozmJ+GcdQmttZX1sgokImGmHyvyUfi6MPeNwGUxxMEAAAAAB4TBAAAAAAeEwQAAAAAXmauQeho8puBYxLZ5CwV7Ich/93kA4FzXjL5byZ/HDiHHYRqvTyTvxU45kWTT03gOhtN/rnJswLn/I/JD5j8SALjwFcKTW4XOGZ+6odRYyKBtjNNbhnHOYAktTI5p0ZGgVrpwkCb3S20h8nnxtHvSJPtz2V2oZkkzTR5eRzXqUV4ggAAAADAY4IAAAAAwGOCAAAAAMDLzDUI/2fyh4FjUrEGYZnJewPH9DLZfgm9/ZA56oynTR6couvYtQ0nmRzaMqPQ5A5JGw0k6WaTl9bIKGpOaC3NcJPtrfG9FI0FmecSk38U4/j1gbb+Ju9KfDioTQaZ/IvAMV8z2S5wWhQ4p5nJE2KMI7Royl43Vf/opwhPEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4mblI2W4UNipwjF2R9LbJj8dxnXdMvszkTwPnnGPy3XFcB1nJLhbuZ3I8G0HZBcULAsfYtVM7TLalH9pnr7fJbFKVXHX9f2KejeMYu8Ef6qbvBNpmmBzrO0hC60n/mtBoUOPqmdzF5GdMPjHQx1smP2yy3SlUit597xWT+wTOsVbGcUwtVtf/3QIAAABwDCYIAAAAADwmCAAAAAC8zFyDYP060FZi8n6Tv2nyDwJ9TDQ5tObAWmvyrXGcg6xgS+r3Jjc02QX6+C+T7b4qPQPn/LvJ9vPee0z+S6CPIybb9RIXBM6xaxvwFbvRXPMaGUXtEc++lfbvC+qmIYG20EZ7x1pk8szkDAW1wT+ZHGtBU+hGcr3JZXFc154Ta83BtkDb83FcpxbjCQIAAAAAjwkCAAAAAI8JAgAAAAAvO9YghMT6jNm+OPr4Z5NnmRz6EDnqhHaBNrsdh/3ctV0LYPcrkKI/snjA5DcC54TaqivP5HsCx9iPhuIrV5hsfz+zXYHJZ8ZxzvZUDAS1XlOTbwkcY9dI7TX5p0kbDWqU3Z9Aku4z2f7cNc1kuyhPim/NgXV/FY+/K9Bm/9HPMDxBAAAAAOAxQQAAAADgMUEAAAAA4GXvGoRYxpncKXCM/dL5S03mi7vrjBNMfixwjP3cuf3Y480mrwz0UVs/q96ypgeQYb4R4/U1aRlFzbF/P0L7QGwwOZGPCSPztDL51QT6eMLkhQmOBTXsAZPtegNJ+tzk/zb5xyZ/Fsd1c0wO7XFg/9GLmPwTk1+L47oZhicIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAALy6u0j5U5OHB475s8nPmBxaGWVXntpNPNhcLSN9y2S7IDnkapPfStJYkPlW1PQAqqBBoO27JttN80Jr/iy7J1I8e1ci89naOT+Oc940+RdJGgvSzO4eervJoZ+P7KLk7yVw3a+bXGxy6EtqrDkm/zyBcWQYniAAAAAA8JggAAAAAPCYIAAAAADw6u4aBOv9QNtQk6ebfFPgHNuWb/ILJu+sfFioHSaabPdMkaTFJmfSmgP7PwVHTA69XySuSZL6sZ/ftn+Ol5h8eqAPuwngjTH6lKSDJi8z+ZDJoX9o/hRoQ3ax67Ak6WcxzvmfQNsQkz9JbDioafZm87U4zrnL5GYmDzP5qkAf55l8ksmhtQ+27UWT7TrWLMQTBAAAAAAeEwQAAAAAHhMEAAAAAB5rECoz3+RSk+0H06XoD/0WmdzK5J8G+vhb5cNC6vUzuaPJoY8svpaaoaSFXXNg3987aRpHtrCf0be/n08FzhmTwHXsGgS7VuSwyaGPza41+TmT7dYuUvR6m10mbzM5L9DHe4E2ZDb7z9urCfQRWg74QQL9oBb63OTdJtv1BZK02eRE9pKyP1PZRSynBs7ZY/KCBK6b4XiCAAAAAMBjggAAAADAY4IAAAAAwGOCAAAAAMBjkXJVrDZ5UOCYK022m6vdanK7QB99qjIopIJdVGn3dwktmvvPFI2luuzYx8VxTonJ9yZnKHXGHSb/n8kXJ+k6fzX51ybbBch2Q7NkGW6yXWsYWniK7PNjk+2XH8Qj1kZqyGD7TB5gcmghsN1VcpPJ9qY3I9DHRybPMjm0SNkeUwfxBAEAAACAxwQBAAAAgMcEAQAAAIDHGoTqsJ+nk6QXTX7WZPs73iPQR0+T7a5EqHGHAm070z6KMLvm4N9NHhU4x25sZfcAPFCtEeHnNT2AFLP7Q1qJbJiF2u+bJieyfM5+hHxDgmNBBlpuckGKrtPdZPszVmixDAuneIIAAAAA4CtMEAAAAAB4TBAAAAAAeKxBqIoOJg8MHNPF5Fi/w/aLyiXprbhHhBryWk0P4Bj2c8B2jcH1JtvP/ErhUgaSZX5NDwAp8TuTG8dxjt2LY2hyhgJUzG5sZNccuMA57IPAEwQAAAAAX2GCAAAAAMBjggAAAADAYw3CUWcF2n5k8vdMPiWB63xp8o7AMaHPwyGtIjHygMA5/5qSkZQ3ItBm9zk42eRik4ckbzgA6rCmJoe+Tt6aajJ7rCDl7GIZxIUnCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAC8urNIubnJ3zf5jsA5rZNw3ZUm/9Tk3yThGkg6u07c5tD69F+Y/JzJH5p8UaCPm0y2m6CdHjjnryb/t8nTAucAqWQX9bcLHPO/6RgIksre0xL5H8YlyRgIUBV9anoAmYknCAAAAAA8JggAAAAAPCYIAAAAALzsWINQEGg71+QnTD47CdddFmibYPKvTWYTtKxQL9B2u8nXmvyJyaHPZceyNNBWYvLYBPoFksne5vifqMxj1z9J0mUm243RPjfZboomSbsSHhGQoK/X9AAyE/dtAAAAAB4TBAAAAAAeEwQAAAAAXmasQWhs8tMmdwyc0yYJ17Vf2DzRZPuF85L0WRKuixpnP+u/wuQucfRh90qwW3GE2L0SZpn8r3H0AdQ23w60PZ/2UaAqGgXaYt3Dtps8KjlDAarn/5ls/2vcLqaBJJ4gAAAAADgGEwQAAAAAHhMEAAAAAB4TBAAAAABezS9SvtDk0Kome0yLJFz3oMm/CBxTZPKnSbguMoJdbHeNybcGzvn3Kl4jVHJPmVxaxT6B2iBS0wMAgKNWm7zR5NCX2tjN1fYkbziZgicIAAAAADwmCAAAAAA8JggAAAAAvJpfg/C9GDke6wJtvzH5S5MfM3lfAtdFnbHT5PGBY0JtQF3wXyZfVyOjQDKtD7TZvUO7pWMgQLLZ9aXPBo75qck/Mjn0c2eW4QkCAAAAAI8JAgAAAACPCQIAAAAAL+KccwmfHAl9eSyyhXPv1/QQolBz2Y2aQ7rVtpqj3rJbbas3qQ7WXAOTXwkcc6nJc00eZnIt3icr0ZrjCQIAAAAAjwkCAAAAAI8JAgAAAACv5vdBAAAAANKhzORBgWPsPgi3mTzO5CzcF4EnCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8FikDAACgbrKLliXprhi5DuAJAgAAAACPCQIAAAAAjwkCAAAAAC/inHM1PQgAAAAAtQNPEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHg1NkHYsmWLIpGIHnvssaT1uWjRIkUiES1atChpfSJ7UHNIN2oO6UbNId2ouexUpQnCjBkzFIlEtHLlylSNp8Zt375dgwYNUqNGjdSwYUNdffXVev/995PS9+jRoxWJRHT99dcHX1+yZInGjRunvXv3Rr1WVFSk+fPnJ2UcFVm3bp2++93v6qSTTlKTJk100003affu3Sm9ZizUXPVQc1VHzVUPNVd11Fz1UHNVR81VT12oOT5idIz9+/erV69eWrx4scaMGaPx48fr7bffVs+ePfXhhx9Wq2/nnF5++WW1bt1av/nNb1RWVhZ1zJIlSzR+/PgaKaht27apR48eKi0tVVFRkUaOHKnXX39dl112mT7//POUXbeuo+aouXSj5qi5dKPmqLl0o+aqX3PHp2yEGWjatGnauHGjli9fri5dukiSLr/8cp133nmaOHGiioqKEu570aJF2rZtm0pKStS3b1/NnTtXQ4YMSdbQyzlw4IDy8/OrdE5RUZEOHDigP/3pT2rZsqUk6cILL9Rll12mGTNm6F/+5V9SMdQ6j5qj5tKNmqPm0o2ao+bSjZpLQs25Kpg+fbqT5FasWFHhMYcOHXIPPPCA+9a3vuUaNmzoTjzxRNetWzdXUlJS7rjNmzc7SW7ChAlu0qRJrmXLli43N9f16NHDvfvuu1H9rlu3zl177bWucePGLicnx3Xq1Mn9+te/LnfMwoULnSS3cOFC33bgwAG3bt06t3v37pjvr0uXLq5Lly5R7X369HFf//rXY55fmR/84AfunHPOcc45d/nll7vLLrus3Otjx451kqJ+Hf19sr+GDBlS7rw1a9a4wYMHu0aNGrmOHTs655zbu3evW7dundu7d2/M8RUUFLjrrrsuqv2ss85yl1xySbXee3VQc4mj5hJDzSWOmksMNZc4ai4x1Fzi6krNJf0jRp988omeffZZFRYW6tFHH9W4ceO0e/du9e3bV++8807U8S+88IIef/xx3XHHHbrvvvu0evVq9e7dW7t27fLHrFmzRhdddJHWrVune++9VxMnTlR+fr4GDBigefPmVTqe5cuXq3379nryyScrPe7IkSP6y1/+os6dO0e9duGFF2rTpk3Bx0jxOHTokF599VUNHjxYkjR48GCVlJRo586d/phrrrnGvz558mTNnDlTM2fOVLNmzTRz5kzl5OSoe/fuvv3WW28td43rrrtOn376qYqKijR8+HBJ0rx589S+ffuYv0fbt2/XBx98UOF7f/vttxN63+lCzUWj5lKLmotGzaUWNReNmkstai5anaq5uKcSLr4Z5+HDh92hQ4fKtX388ceuefPm7pZbbvFtR2dSeXl5btu2bb592bJlTpIbMWKEb7vkkktchw4d3Geffebbjhw54i6++GLXrl073xaacR5tGzt2bKXvbffu3U6Se+ihh6Jemzp1qpPk1q9fX2kfFZkzZ46T5DZu3Oicc+6TTz5xubm5bvLkyeWOmzBhgp9lWvn5+X6WeayjM87BgwdHvXb0z2v69OmVjm/FihVOknvhhReiXhs1apSTVO73Pp2oOWou3ag5ai7dqDlqLt2oOWoulqQ/QahXr55OOOEESX+fxX300Uc6fPiwOnfurD//+c9Rxw8YMEAtWrTw+cILL1TXrl31xhtvSJI++ugjlZSUaNCgQSorK9OePXu0Z88effjhh+rbt682btyo7du3VziewsJCOec0bty4Ssd98OBBSVJOTk7Ua7m5ueWOqari4mJ17txZbdu2lSQ1aNBA/fr1U3FxcUL9hfzwhz+Mahs6dKiccxo6dGil56byvacDNReNmkstai4aNZda1Fw0ai61qLlodanmUvItRs8//7zOP/985ebmqmnTpmrWrJlef/117du3L+rYdu3aRbWdddZZ2rJliySptLRUzjk98MADatasWblfY8eOlSR98MEH1R5zXl6epL8/PrI+++yzcsdUxd69e/XGG2+oZ8+eKi0t9b++853vaOXKldqwYUP1Bv4PZ555ZsLnpuq9pxM19xVqLj2oua9Qc+lBzX2FmksPau4rda3mkv4tRi+++KKGDh2qAQMGaNSoUSooKFC9evX0yCOPaNOmTVXu78iRI5KkkSNHqm/fvsFjjs7kqqNJkybKycnRjh07ol472nbaaadVud/Zs2fr0KFDmjhxoiZOnBj1enFxscaPH1/1ARvVucmceuqpklThez/6e1NbUXPlUXOpR82VR82lHjVXHjWXetRceXWt5pI+QZgzZ47atGmjuXPnKhKJ+Pajs0Nr48aNUW0bNmxQ69atJUlt2rSRJNWvX1+XXnppsofrHXfccerQoUNw05Bly5apTZs2atCgQZX7LS4u1nnnnRd8/08//bReeuklX1DH/n5Zlb1WXS1atFCzZs2C73358uXq2LFjyq6dDNRcedRc6lFz5VFzqUfNlUfNpR41V15dq7mUrEGQJOecb1u2bJmWLl0aPH7+/PnlPnO2fPlyLVu2TJdffrkkqaCgQIWFhXr66aeDM6JYO8N9+umnWr9+vfbs2RNz7AMHDtSKFSvK/ca+9957Kikp0XXXXRfzfGvr1q166623NGjQIA0cODDq17Bhw1RaWqply5ZJkv+u29DGGvn5+cH2yuzbt0/r168PPgq0rr32Wi1YsEBbt271bW+++aY2bNiQ0HtPJ2ruK9RcelBzX6Hm0oOa+wo1lx7U3FfqZM3FtZT5H46uor7tttvcww8/HPXrk08+cc8995yT5K666ir39NNPu3vvvdc1atTInXvuua5Vq1a+r6Or3jt06OBat27tHn30UffQQw+5Jk2auKZNm7q//e1v/tg1a9a4xo0bu6ZNm7p7773X/epXv3IPP/ywu+KKK9z555/vj6vOqnfn/r4a/etf/7orKChwP//5z93kyZPdGWec4U477TT3wQcflDu2Z8+eLtZv389+9jMnyb3zzjvB1z/++GN3/PHHux/96EfOOeeWL1/uJLkrrrjCvfDCC+7ll192+/fvd845d8UVV7j8/Hw3ceJE9/LLL7v//d//dc59teo99L3A8a56d865v/71r65p06bu61//unv88cddUVGRa9y4cdS3DaQbNfcVai49qLmvUHPpQc19hZpLD2ruK9RcWEIThIp+bd261R05csQVFRW5Vq1auZycHHfBBRe4BQsWuCFDhgQLasKECW7ixInujDPOcDk5Oa579+5u1apVUdfetGmTu/nmm90pp5zi6tev71q0aOH69+/v5syZ44+pbkE559zWrVvdwIEDXcOGDd1JJ53k+vfv77/O6lidOnVyp5xySqV9dejQwbVs2bLSYwoLC11BQYH74osvnHPOPfzww65FixbuuOOOK/cVWevXr3c9evRweXl5ToreWKO6BeWcc6tXr3Z9+vRxJ554omvUqJG78cYb3c6dO+M6N1Woua9Qc+lBzX2FmksPau4r1Fx6UHNfoebCIs4d8+wIcSkrK1OTJk00ZcoU3XHHHTU9HNQB1BzSjZpDulFzSDdqrmIp+ZrTbPfWW2+pRYsWfoc7INWoOaQbNYd0o+aQbtRcxXiCAAAAAMDjCQIAAAAAjwkCAAAAAI8JAgAAAACPCQIAAAAA7/jqnByJtEnWOFALOfd+TQ8hCjWX3ag5pFttqznqLbvVtnqTqLlsl2jN8QQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgHd8TQ8AqKumBNruMnm1yf0D5/w1KaMBAADp8odAW8TkS9IxkArwBAEAAACAxwQBAAAAgMcEAQAAAIDHGoRqOCmOtn4mF5g8MdDH5wmPCLVZK5P/KXDMEZPbm3x24BzWIKAi7UyuHzimh8nTTLY1mSy/NvkGk79I0XWRPqEfMC42ucjkbikaC1DTJpls/y5I0gvpGEiceIIAAAAAwGOCAAAAAMBjggAAAADAY4IAAAAAwGORciVamzza5G8Hzjmvitc4JdB2dxX7QGbYbfJbgWOuSsdAkDXOMXmoydeZHPofodNMtouSXRXHFC9b60+Z/K+Bc8pSMxSkyMmBtoUm7zS5eeCcXckZDpBWj5j8Q5NDX8TwZorGkgieIAAAAADwmCAAAAAA8JggAAAAAPDq7BqEb5j8r4Fj7EZWuSZHAudsNdl+ZtZufDUo0IfdqOi9wDHIPJ+a/H81MgpkE/sZ1ytqZBTJcbPJ/xE4Zkk6BoK0suvwQuvyWIOATHSRyXajyv8JnDM7RWNJBE8QAAAAAHhMEAAAAAB4TBAAAAAAeFm7BqGhyY+afL3JDRK4xsZAW1+TTzB5nclfC/Rh21iDkB3sd4J/s0ZGgWzye5NjrUH4IND2nMl2bVU8+yDYPWF6xnEOIIXX8gGJ6h5ou9/kwSZ/nITr3hBos/tibTJ5ZBKum0o8QQAAAADgMUEAAAAA4DFBAAAAAOAxQQAAAADgZe0i5e+Z/M9J6NMuMLkscMw2k9sm4brIDiea3DKBProE2tab/NcE+kVm+qXJ82Mc/0WgLRmbUNkveVht8mlx9DHf5JUJjwaZxC6Cz6uRUSBb/CrQ1s7kc0z+YxKuaxdCS1JTk4eb/JckXDeVeIIAAAAAwGOCAAAAAMBjggAAAADAy9o1CNdV8fgtgbYVJv/YZLveIOTsKo4D2WuHyTMCx4yL0Ufo9b0mT41rNMgGX5oczz0pFewGkY0T6MOO/fMEx4LM1inQ9r9pHwUy1aeBNrvOJTcJ17EbnYbWFB5JwXXTiScIAAAAADwmCAAAAAA8JggAAAAAvKxdg2C/b/ZfTP6dyaWBPnYnYRzNk9AHstNPAm3j0j0IIAHXm2zvt4l8l/2DCY4FtdfhQNs+k082+espGguy00MmdwgcY/cKWpXAdew+RnZNqn1dil47MyeB69YkniAAAAAA8JggAAAAAPCYIAAAAADwsnYNgv3O+fE1Mgrp2zV0XWQmO2O336MMpNr3Tb4vcIz9nHj9BK7zjslfJNAHaje73kCS/p/J/dMxEGSN0022659C617uMHlPAtedZLLda+tvgXO6JXCd2oQnCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAC8rF2knAw/Mjnf5EjgHGdyaNOOYy0JtC2NcQ6yl12UbOsJOFYrk28y+dIE+rQL6xKpwU9MvjdwzBsmf5bAdQBkt/NMnmvy10x+ItDHWwlc9x6Th8Y4/qcJXKO24wkCAAAAAI8JAgAAAACPCQIAAAAAr86sQcgz+VyTHwycc0WMPkOzq1gbW9kN3IYl0AeAusd+FleSfm1yy3QMJA52M6xnamQUyERNa3oASJt6Jv9T4Jj/MDnWZqKhzWntZo8TTW4SOMduhGbXnL5g8q8CfWQ6niAAAAAA8JggAAAAAPCYIAAAAADwsmINQuhNXGDyqyafavLBQB92vYDds+C7gXNODLQdy37m7prAMb8w+YsYfQKom+znYkN7s1RVrM/4xqO/yZcHjvmvBPpF9ruqpgeAtLnB5GcDx9h9WOz9qNTkzoE+bJutsRaBc+zPiLtN/kHgnGzDEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAXkYuUq5vcmix8NwYfYw3uSRwjF2U3DiOc0KbGR2rmcmPBI75q8nzTf48xjWQuRJZINrD5KlJGgtql9WBtkKT7UZD/23yZ0kai12g96Mk9Yvst9Bku6Ad2WuQydNNDn0hy16Tv2/yxybbTdAkqafJdtFy6Msd7OLor5lsf04rDPTxfqAtk/AEAQAAAIDHBAEAAACAxwQBAAAAgJcRaxDsIO36gVFx9PFbk58weV/gHPuZszdM7hA4x64P+LnJdo3C1YE+ik3+Q4w+pejP4VnvxHgdtYNdc2A/BxliN9trb/K6xIeDWs5+DrYoTdcdZzJrEBAvW7OWXWMoSS2r2Adqp1tNtn+OPw2cY9cpxBK6F/3K5Iuq2KcUvU7BrqXJ9PUGITxBAAAAAOAxQQAAAADgMUEAAAAA4NW6NQihGcvDJo80+UDgnPtMftlku+bAfi+uFL1O4QKTNwbOuc3kRSY3MPniQB83mnyVyb8LnGNtNblNHOeg5j1lsv3MZjz+xeQRCY4FqEjfmh4AMtbhGK+HvpM+JxUDQdr92mS7X9W2JFzDrh2VpHNjnDM40Bbad+ZYyRhrbccTBAAAAAAeEwQAAAAAHhMEAAAAAF6tW4NgPz8tRa85+NTk0Oe07ef07ffeDjP5ikAfuSY/ZHLo+3ljfS6tzOT/Dhxj224w2a5RCOFz55lpfU0PADXG3oz7mFwSOOezFI3lWPZeKUlT0nBdZKfXTLb3vLMD5/yryXckbTRIp8dT0GdDkwfFccwmk2cnbzhZhScIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAALyIc84lfHIk+dtv/S3Q1szkQyaHFnbmm9w2gbGMM/kRk48k0Gcmce79mh5ClFTUXG32nslfj+McO+u3tV/7/lS/UldqrlugbYzJl5l8ZuCcZGzW09hk+4UNdsNIKXrDR+ugyXazRyl6E8maUttqrq7d4yabHFoU39xk+zNAJqlt9SZlds3da7LdWFeSdpvcxeTtyRtOrZRozfEEAQAAAIDHBAEAAACAxwQBAAAAgFfrNkrbGWizaxByTP5mHP2+YfJbJs8PnLPF5Gxfc4DaZ43J8XxSlDqt/UKf6z8vxjmjA21248VE2LUO3zI5nkVqi0z+ZYzXgYqE6u3ztI8CtVVLk//Z5FD9/MrkbF9zkCw8QQAAAADgMUEAAAAA4DFBAAAAAODVujUIPQJtA0y2n5H9IHDOcyZ/bPIXVRgTUFPsZyevrJFRoDa4rYauG7q//sbku03O5O+pR81qGGgbYPK8NIwDtdPvTW5l8ouBc8alZihZjycIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAALxat0h5f6DNLjoJLUIBstFak9cFjmmfjoEgqYYF2u40eUgKrrsp0Papyf/P5GcC56xOznAADTI5tMDd3gdRd80w+SGTX0vTOOoCniAAAAAA8JggAAAAAPCYIAAAAADwat0aBABf+avJ59fIKJBs7wTabjd5uck/CZzT2OT5JttNhX4d6GNXoA1Il7dMDq2pOpiOgSAjPBIjI3l4ggAAAADAY4IAAAAAwGOCAAAAAMBjDQIA1AKfm/yrGBnIBoNregAAgniCAAAAAMBjggAAAADAY4IAAAAAwGOCAAAAAMBjggAAAADAY4IAAAAAwGOCAAAAAMBjggAAAADAY4IAAAAAwGOCAAAAAMBjggAAAADAY4IAAAAAwIs451xNDwIAAABA7cATBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAF6NTRC2bNmiSCSixx57LGl9Llq0SJFIRIsWLUpan8ge1BzSjZpDulFzSDdqLjtVaYIwY8YMRSIRrVy5MlXjqXHbt2/XoEGD1KhRIzVs2FBXX3213n///aT0PXr0aEUiEV1//fXB15csWaJx48Zp7969Ua8VFRVp/vz5SRlHRdatW6fvfve7Oumkk9SkSRPddNNN2r17d0qvGUu219x7772nESNG6OKLL1Zubq4ikYi2bNmStP6nTZumSCSirl27Bl9fu3atxo0bF7zmtGnTNGPGjKSNxUr1e09UttecxH2O+1x6cZ/jPlcTuM9V7z7HR4yOsX//fvXq1UuLFy/WmDFjNH78eL399tvq2bOnPvzww2r17ZzTyy+/rNatW+s3v/mNysrKoo5ZsmSJxo8fXyMFtW3bNvXo0UOlpaUqKirSyJEj9frrr+uyyy7T559/nrLr1nVLly7V448/rrKyMrVv3z7p/RcXF6t169Zavny5SktLo15fu3atxo8fXyP/cKb6vSOM+xz3uXTjPsd9Lt24z1X/PscE4RjTpk3Txo0btWDBAo0ePVojRozQ7373O+3YsUMTJ06sVt+LFi3Stm3b9Nxzz+nw4cOaO3dukkYd7cCBA1U+p6ioSAcOHFBJSYnuuusujRkzRq+88opWrVqV0ptnXXfVVVdp7969evfdd3XjjTcmte/NmzdryZIlmjRpkpo1a6bi4uKk9n+sRGoule8dFeM+x30u3bjPcZ9LN+5z1b/PJX2C8Pnnn+vBBx9Up06ddPLJJys/P1/du3fXwoULKzxn8uTJatWqlfLy8tSzZ0+tXr066pj169dr4MCBatKkiXJzc9W5c2e99tprMcfz6aefav369dqzZ0/MY+fMmaMuXbqoS5cuvu3ss8/WJZdcoldeeSXm+ZUpLi7WOeeco169eunSSy+NuomNGzdOo0aNkiSdeeaZikQi/lFkJBLRgQMH9Pzzz/v2oUOH+vMikYjWrl2r73//+2rcuLG6desmSdq3b5/Wr1+vffv2xRzfq6++qv79+6tly5a+7dJLL9VZZ51V7feeaplcc02aNFGDBg1iHpeI4uJiNW7cWP369dPAgQOjam7GjBm67rrrJEm9evXytbVo0SK1bt1aa9as0eLFi317YWGhPy8SiWjx4sW6/fbbVVBQoNNPP11S7XnvqZbJNcd9jvvcsbjPcZ+rSCbXHPe56t/nkj5B+OSTT/Tss8+qsLBQjz76qMaNG6fdu3erb9++euedd6KOf+GFF/T444/rjjvu0H333afVq1erd+/e2rVrlz9mzZo1uuiii7Ru3Trde++9mjhxovLz8zVgwADNmzev0vEsX75c7du315NPPlnpcUeOHNFf/vIXde7cOeq1Cy+8UJs2bQo+RorHoUOH9Oqrr2rw4MGSpMGDB6ukpEQ7d+70x1xzzTX+9cmTJ2vmzJmaOXOmmjVrppkzZyonJ0fdu3f37bfeemu5a1x33XX69NNPVVRUpOHDh0uS5s2bp/bt28f8Pdq+fbs++OCDCt/722+/ndD7TpdMrblUKy4u1jXXXKMTTjhBgwcP1saNG7VixQr/eo8ePXTXXXdJksaMGeNrq3379poyZYpOP/10nX322b79/vvvL9f/7bffrrVr1+rBBx/UvffeK6n2vPdUy9Sa4z7HfY77HPe5eGVqzXGfS9J9zlXB9OnTnSS3YsWKCo85fPiwO3ToULm2jz/+2DVv3tzdcsstvm3z5s1OksvLy3Pbtm3z7cuWLXOS3IgRI3zbJZdc4jp06OA+++wz33bkyBF38cUXu3bt2vm2hQsXOklu4cKFUW1jx46t9L3t3r3bSXIPPfRQ1GtTp051ktz69esr7aMic+bMcZLcxo0bnXPOffLJJy43N9dNnjy53HETJkxwktzmzZuj+sjPz3dDhgyJah87dqyT5AYPHhz12tE/r+nTp1c6vhUrVjhJ7oUXXoh6bdSoUU5Sud/7dMrmmrMq+/OvqpUrVzpJ7ve//70f++mnn+7uvvvucsfNnj07avxHnXvuua5nz55R7Uf/TLp16+YOHz5c7rXa8N6rK5trjvsc9znuc+Vxn8u+muM+l5z7XNKfINSrV08nnHCCpL/P4j766CMdPnxYnTt31p///Oeo4wcMGKAWLVr4fOGFF6pr16564403JEkfffSRSkpKNGjQIJWVlWnPnj3as2ePPvzwQ/Xt21cbN27U9u3bKxxPYWGhnHMaN25cpeM+ePCgJCknJyfqtdzc3HLHVFVxcbE6d+6stm3bSpIaNGigfv36JfWzkj/84Q+j2oYOHSrnnH98VZFUvvd0yNSaS6Xi4mI1b95cvXr1kiT/bQuzZs3Sl19+mZRrDB8+XPXq1SvXVhveezpkas1xn+M+x32uarjPZV7NcZ9LzntPySLl559/Xueff75yc3PVtGlTNWvWTK+//nrws1Pt2rWLajvrrLP8tw2UlpbKOacHHnhAzZo1K/dr7NixkqQPPvig2mPOy8uT9PfHR9Znn31W7piq2Lt3r9544w317NlTpaWl/td3vvMdrVy5Uhs2bKjewP/hzDPPTPjcVL33dMrEmkuVL7/8UrNmzVKvXr20efNmX3Ndu3bVrl279OabbyblOtWpuWyQiTXHfY77HPe5quE+l3k1x30uOe/9+IRHUYEXX3xRQ4cO1YABAzRq1CgVFBSoXr16euSRR7Rp06Yq93fkyBFJ0siRI9W3b9/gMUdnctXRpEkT5eTkaMeOHVGvHW077bTTqtzv7NmzdejQIU2cODG4cr64uFjjx4+v+oCN6vzDduqpp0pShe/96O9NbZWpNZcqJSUl2rFjh2bNmqVZs2ZFvV5cXKw+ffpU+zq1/YepVMrUmuM+x33uKO5z8eE+l3k1x30uOfe5pE8Q5syZozZt2mju3LmKRCK+/ejs0Nq4cWNU24YNG9S6dWtJUps2bSRJ9evX16WXXprs4XrHHXecOnToENw0ZNmyZWrTpk1C30RQXFys8847L/j+n376ab300ku+oI79/bIqe626WrRooWbNmgXf+/Lly9WxY8eUXTsZMrXmUqW4uFgFBQWaOnVq1Gtz587VvHnz9NRTTykvL6/Gai7TZWrNcZ/jPsd9rjzucxXL1JrjPpec+1xK1iBIf99I4qhly5Zp6dKlwePnz59f7jNny5cv17Jly3T55ZdLkgoKClRYWKinn346OCOKtTNcVb4Wa+DAgVqxYkW539j33ntPJSUl/mvSqmLr1q166623NGjQIA0cODDq17Bhw1RaWqply5ZJkvLz8yUpuLFGfn5+sL0yVflarGuvvVYLFizQ1q1bfdubb76pDRs2JPTe0ymTay7ZDh48qLlz56p///7BmrvzzjtVVlbmv1Iu2TVXk+89nTK55rjPcZ+TuM8dxX2uYplcc9znqn+fS+gJwnPPPaff/va3Ue133323+vfvr7lz5+p73/ue+vXrp82bN+upp57SOeeco/3790ed07ZtW3Xr1k233XabDh06pClTpqhp06YaPXq0P2bq1Knq1q2bOnTooOHDh6tNmzbatWuXli5dqm3btmnVqlUVjnX58uXq1auXxo4dG3Nhy+23365nnnlG/fr108iRI1W/fn1NmjRJzZs31z333FPu2MLCQi1evLjcXxzrpZdeknNOV111VfD1K664Qscff7yKi4vVtWtXderUSZJ0//3364YbblD9+vV15ZVXKj8/X506ddIf/vAHTZo0SaeddprOPPPMCreVP2revHkaNmyYpk+fHnNhy5gxYzR79mz16tVLd999t/bv368JEyaoQ4cOGjZsWKXnpkO21ty+ffv0xBNPSJL++Mc/SpKefPJJNWrUSI0aNdKdd97pjx06dKief/55bd682f+PjPXaa6+prKyswpq76KKL/GZC119/vTp27Kh69erp0Ucf1b59+5STk6PevXuroKBAnTp10i9/+Uv95Cc/Udu2bVVQUKDevXtX+n5S9d5rQrbWHPc57nNHcZ/jPpetNcd9Lgn3ubi+6+gfjn7NUkW/tm7d6o4cOeKKiopcq1atXE5OjrvgggvcggUL3JAhQ1yrVq18X0e/FmvChAlu4sSJ7owzznA5OTmue/fubtWqVVHX3rRpk7v55pvdKaec4urXr+9atGjh+vfv7+bMmeOPScZXsW3dutUNHDjQNWzY0J100kmuf//+/uusjtWpUyd3yimnVNpXhw4dXMuWLSs9prCw0BUUFLgvvvjCOefcww8/7Fq0aOGOO+64cl+RtX79etejRw+Xl5fnJPmvyDr6tVi7d++O6jver8U6avXq1a5Pnz7uxBNPdI0aNXI33nij27lzZ1znpkq219zRMYV+HTt255y79tprXV5envv4448r7O/KK690ubm57sCBAxUeM3ToUFe/fn23Z88e55xzzzzzjGvTpo2rV69eufeyc+dO169fP9egQQMnyX8VYGVfj5eq955O2V5zznGf4z73Fe5z3Oeyseac4z5X3ftcxLlKpkwIKisrU5MmTTRlyhTdcccdNT0c1BHNmzfXzTffrAkTJtT0UFAHcJ9DTeA+h3TiPlexlHzNabZ766231KJFC7/DHZBqa9as0cGDB/XjH/+4poeCOoL7HNKN+xzSjftcxXiCAAAAAMDjCQIAAAAAjwkCAAAAAI8JAgAAAACPCQIAAAAAL6GN0o6KRNokaxyohZx7v6aHEIWay27UHNKtttUc9Zbdalu9SdRctku05niCAAAAAMBjggAAAADAY4IAAAAAwGOCAAAAAMBjggAAAADAY4IAAAAAwGOCAAAAAMBjggAAAADAq9ZGaQAAACnVzuTfmlzP5NapGwpQV/AEAQAAAIDHBAEAAACAxwQBAAAAgMcaBAAAUDs8Hmi73uQmJi9I0ViAOownCAAAAAA8JggAAAAAPCYIAAAAALw6uwbhHJP7B44ZbvIKk9+J4zpTTP48jnMAAMhKBSbPNfmiwDnO5NUm/6BaIwIQwBMEAAAAAB4TBAAAAAAeEwQAAAAAXp1Zg3CryRNMPimOPr5u8g1xnLPS5JI4zgGQ2fJNtl/j/lngnE4mNzD5xsA5i0zeXvmw4rLT5F8HjvlTEq6DOqBdoO0xk7vG0c99Jtt/WD+Ke0TIMhGTXwocc4XJdg1qMu6b2YgnCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAC8OrNIebbJ402OZ5FyIuaYbBc2/y5F1wVQcx40eWSKrvPdFPV7LLs+VJLWmjzL5JdN3pK00SCjNA202RWj8dhm8qIE+kBWyjW5W+AY+/OdvW/+R/KGk1V4ggAAAADAY4IAAAAAwGOCAAAAAMCrM2sQ7D4q40y2e7dI0okm/9XklnFct5HJfU1mDQJqBVvMeSYPDpxzW4w+Xzf5liqNKKNdk4Q+PjT5L0no871A2zdMbmTyBYFzzjP5JyavMnlLpaNC1rAboxUHjrE7W1mhvzyvJTYcZL+DJm8IHHOayQUpGku24QkCAAAAAI8JAgAAAACPCQIAAAAAr86sQbCeMvnWwDHfNPmTJFx3ahL6AKrkEpNDn/G1awxONtklcN2LEjgnS9i1RvZz/qG1ANanJu9MfDhVYr8z/N3AMbHWX11l8huJDweZ5CaTQ4Vii+GHJv8tecNB3RP6GavQ5LPTMI5swBMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAF6dXaRs/TTQNsbkjkm4Tk4S+gDKecbkDiZ3SaDPMpNDGx6tNPklkw8lcN0s8X6MXJtdaXI8G0LaP+pnkzQW1HJ/NLmjyVsC5/ybySxKRhItj+OYQSb/OHBMur4UojbjCQIAAAAAjwkCAAAAAI8JAgAAAACPNQj/MCfQ9j8m/7fJ9qPe8XjI5OsS6AN1SBOTHwkcc4vJH5n8J5N/FuhjtckHTd4aOAcZp36g7XGTb06g34tNfieBPpAB7A54XU22GyrODvRh7y1AikVMPsFkW9aS9KsUjSWT8AQBAAAAgMcEAQAAAIDHBAEAAACAxxqEf7gx0Ha+yecl4Tr2a6OBSj1g8g8Cxzxh8v0mH0jecJBZepn8T4Fjhsbo44tA210mr4t3QMgcJwfaulexj48DbdsTGItlC/CMOM4ZlYTrIiPZpTGWXZOAv+MJAgAAAACPCQIAAAAAjwkCAAAAAK/OrEE42+S5JrcNnJOK35zXUtAnMkSeyT8OHHOTyf9q8sLAOXaDjkNVGBOySheTbWnUS6DP0Od37bYYXybQL2q50B9qJ5PtfzEeMfmtBK47ItBmi/BHJreKo997TD7d5L/F0QdQh/AEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIBXZxYptzf5TJPT9Rvxrybb/V6Qxf7d5NAi5VdM/p3JLEBGJQaZnMiiZCu0idACk1ea/BuT5wf6WJ3ogJAePQNtdqM0uyj5ryZ/GMd1vmlyt8AxV8Xow24GuS1wzDdMnmPyDYFz7PsB6hCeIAAAAADwmCAAAAAA8JggAAAAAPDqzBqEeSbbj3//LHBObgrGcWoK+kSGuM/k0A5UL5vMmgNUgd0A0q69shupSdLXknDdzjHy2MA5U0z+ucm7qzMgVN1JJtuFeiE7TJ5pcmngnHYmjzL56sA5e0z+vckTTW4Y6KPE5JMDxyArRUwO/dOLaDxBAAAAAOAxQQAAAADgMUEAAAAA4NWZNQjW4yZvDBzTKEYfod+8J0wOfRQSddRyk+0HtSXpSZMPmvyH5A0H2Wepyf1NPiNwjl2D0NzkawLn3GKy/YyvFfqfqH8zuZPJlwTO4bPDKWT3H5gcxzm/MvlhkwsC5zxm8hUmlwXOmW3yPSbbdQ1PBfqw/do1Cex5kLW4bySGJwgAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAvDq7SNn6rwTOCS3M+7rJD5rc0eRWgT7+L4GxIM0uDLS9bfIXJl9u8l2BPh4weY7JFwXOWR9oAwK2xtl2rN8G2haZ/COTQ389Yulp8sjAMRMS6BdxOj+Bc+yiZMvu3CdJXWOcE9oo7S2T7X3w/8XoU4remc9u0IY66y81PYBaiicIAAAAADwmCAAAAAA8JggAAAAAPNYgVMMJgTa75sCyH0v/MkljQZKdYvICk1sGzhlhcrHJH5tsN0WTotcgnGRy48A5QJq9ZPJ/mmz38+uRwDXaJnAOqqGRyaFFdr+O0cc3TW4dOMb2azc9s+sNpOiN0Oy9NVafkvSLQBsgaVNND6CW4gkCAAAAAI8JAgAAAACPCQIAAAAAjzUI1RDrK6BDnjN5WzIGguT7s8kNTf5x4Bz7udhY/jWOY+yHuVdX8RpAGti1VH8yOZE1CBsSHAuSxMXZVpkjcfRh918IbQSUa/Jmk7ubvC/GuADExBMEAAAAAB4TBAAAAAAeEwQAAAAAXkasQWhqsv0cv/0Obin6e7qT4VST/yWBPuYmYyBIvcdN/vcYr1fUdqyNJtvv9paiP397n8llMa6BrGW35pCk4SavN3l2isZi2f9psl+HH4/DJi9LcCxI0Gsmjwocc7XJF5ls/+AbxHHdm00O7b+wx+TxJv8tjusAFcip6QHUUjxBAAAAAOAxQQAAAADgMUEAAAAA4DFBAAAAAOBlxCLlX5h8pclnBc7ZHiOXmtwp0Ift167ZsntnhUw0mbVUGeJnJn9h8gWBcy6N0Wdjk98IHHOPybZQUWc0N/m3gWM6mGxLLFUKTP43k3sn0Oc6k/8ngT5QDZ+b/GngmBNNtn9IVd1ILST0RQx2tf1/JeE6wD9cEWh7Mu2jqH14ggAAAADAY4IAAAAAwGOCAAAAAMDLiDUIU00+0+RvB85ZaPIWk9ea3D3QR6w9XkIft7QbFY0z+bMYfaKWsotJgBSbYrJdbxBi743vmRzP/SfX5NGBY+yag1j3ytDeV/aj5nfF6AMp9meTBweOsX/whQlc53mT3zX57cA5byVwHdRJuwJt9ue9c9IxkCzAEwQAAAAAHhMEAAAAAB4TBAAAAABeRqxBWBojvxg4x65baB0jJ+LjQNu5SegXAN40eVAc59iPkduPc++Lo4+TTQ5t+VFVoa+2/57JfMy8lgnt0xJqA2oRu2WRJB2Mcc5lgTb2QeAJAgAAAIBjMEEAAAAA4DFBAAAAAOAxQQAAAADgZcQiZWukyTmBY06K0UdHk0N7wlh2gV+fOM4BgET8weRZgWNuiNFHMhYYx+OwyVNMfjVwzvLUDAUAynnH5E4mx/p5sa7iCQIAAAAAjwkCAAAAAI8JAgAAAAAvI9cgWIcCbROq2MeNyRgIACTJFpOHBY55zeTeJm8w+ao4rrs+jmNKTH7P5Hfi6AMA0uGnJp9n8ivpGkiG4QkCAAAAAI8JAgAAAACPCQIAAAAAL+KccwmfHGmTzLGglnHu/ZoeQhRqLrtRc0i32lZz1Ft2q231JlFz2S7RmuMJAgAAAACPCQIAAAAAjwkCAAAAAI8JAgAAAACPCQIAAAAAjwkCAAAAAI8JAgAAAACPCQIAAAAAjwkCAAAAAI8JAgAAAACPCQIAAAAAjwkCAAAAAC/inHM1PQgAAAAAtQNPEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHg1NkHYsmWLIpGIHnvssaT1uWjRIkUiES1atChpfSJ7UHNIN2oO6UbNIZ2ot+xVpQnCjBkzFIlEtHLlylSNp0a99957GjFihC6++GLl5uYqEoloy5YtSet/2rRpikQi6tq1a/D1tWvXaty4ccFrTps2TTNmzEjaWKxUv/dEZXvNSdL27ds1aNAgNWrUSA0bNtTVV1+t999/Pyl9jx49WpFIRNdff33w9SVLlmjcuHHau3dv1GtFRUWaP39+UsZRkXXr1um73/2uTjrpJDVp0kQ33XSTdu/endJrxpLtNcd9jvtculFztavmqLfqqSv1xkeMjrF06VI9/vjjKisrU/v27ZPef3FxsVq3bq3ly5ertLQ06vW1a9dq/PjxNVJUqX7vCNu/f7969eqlxYsXa8yYMRo/frzefvtt9ezZUx9++GG1+nbO6eWXX1br1q31m9/8RmVlZVHHLFmyROPHj6+RCcK2bdvUo0cPlZaWqqioSCNHjtTrr7+uyy67TJ9//nnKrlvXcZ/jPpdu1Bw1l07UW3LeOxOEY1x11VXau3ev3n33Xd14441J7Xvz5s1asmSJJk2apGbNmqm4uDip/R/rwIEDVT4nle8dFZs2bZo2btyoBQsWaPTo0RoxYoR+97vfaceOHZo4cWK1+l60aJG2bdum5557TocPH9bcuXOTNOpoidRcUVGRDhw4oJKSEt11110aM2aMXnnlFa1atSqlN9C6jvsc97l0o+aouXSi3pLz3pM+Qfj888/14IMPqlOnTjr55JOVn5+v7t27a+HChRWeM3nyZLVq1Up5eXnq2bOnVq9eHXXM+vXrNXDgQDVp0kS5ubnq3LmzXnvttZjj+fTTT7V+/Xrt2bMn5rFNmjRRgwYNYh6XiOLiYjVu3Fj9+vXTwIEDo4pqxowZuu666yRJvXr1UiQS8Z/Ba926tdasWaPFixf79sLCQn9eJBLR4sWLdfvtt6ugoECnn366pNrz3lMtk2tuzpw56tKli7p06eLbzj77bF1yySV65ZVXYp5fmeLiYp1zzjnq1auXLr300qiaGzdunEaNGiVJOvPMM31tHf1M6YEDB/T888/79qFDh/rzIpGI1q5dq+9///tq3LixunXrJknat2+f1q9fr3379sUc36uvvqr+/furZcuWvu3SSy/VWWedVe33nmqZXHPc57jPHYuao+ZCqLewulRvSZ8gfPLJJ3r22WdVWFioRx99VOPGjdPu3bvVt29fvfPOO1HHv/DCC3r88cd1xx136L777tPq1avVu3dv7dq1yx+zZs0aXXTRRVq3bp3uvfdeTZw4Ufn5+RowYIDmzZtX6XiWL1+u9u3b68knn0z2W62S4uJiXXPNNTrhhBM0ePBgbdy4UStWrPCv9+jRQ3fddZckacyYMZo5c6Zmzpyp9u3ba8qUKTr99NN19tln+/b777+/XP+333671q5dqwcffFD33nuvpNrz3lMtU2vuyJEj+stf/qLOnTtHvXbhhRdq06ZNwY8FxePQoUN69dVXNXjwYEnS4MGDVVJSop07d/pjrrnmGv/65MmTfW01a9ZMM2fOVE5Ojrp37+7bb7311nLXuO666/Tpp5+qqKhIw4cPlyTNmzdP7du3j/l7tH37dn3wwQcVvve33347ofedLplac6nGfS51qLkwai41qLewOlVvrgqmT5/uJLkVK1ZUeMzhw4fdoUOHyrV9/PHHrnnz5u6WW27xbZs3b3aSXF5entu2bZtvX7ZsmZPkRowY4dsuueQS16FDB/fZZ5/5tiNHjriLL77YtWvXzrctXLjQSXILFy6Mahs7dmxV3qqbMGGCk+Q2b95cpfNCVq5c6SS53//+937sp59+urv77rvLHTd79uyo8R917rnnup49e0a1H/0z6datmzt8+HC512rDe6+ubK653bt3O0nuoYceinpt6tSpTpJbv359pX1UZM6cOU6S27hxo3POuU8++cTl5ua6yZMnlzuusj/r/Px8N2TIkKj2sWPHOklu8ODBUa8d/fOaPn16peNbsWKFk+ReeOGFqNdGjRrlJJX7vU+nbK45i/sc9zlqru7VHPWWmLpWb0l/glCvXj2dcMIJkv7+P6QfffSRDh8+rM6dO+vPf/5z1PEDBgxQixYtfL7wwgvVtWtXvfHGG5Kkjz76SCUlJRo0aJDKysq0Z88e7dmzRx9++KH69u2rjRs3avv27RWOp7CwUM45jRs3LrlvtAqKi4vVvHlz9erVS5L8t8rMmjVLX375ZVKuMXz4cNWrV69cW2147+mQqTV38OBBSVJOTk7Ua7m5ueWOqari4mJ17txZbdu2lSQ1aNBA/fr1S+rnJX/4wx9GtQ0dOlTOOf9xpIqk8r2nQ6bWXCpxn0stai4aNZc61Fu0ulZvKVmk/Pzzz+v8889Xbm6umjZtqmbNmun1118Pfi65Xbt2UW1nnXWWX/1dWloq55weeOABNWvWrNyvsWPHSpI++OCDVLyNpPjyyy81a9Ys9erVS5s3b1ZpaalKS0vVtWtX7dq1S2+++WZSrnPmmWcmpZ9MlYk1l5eXJ+nvHweyPvvss3LHVMXevXv1xhtvqGfPnr7eSktL9Z3vfEcrV67Uhg0bqjfwf6hOzaXqvadTJtZcqnCfSw9q7ivUXOpRb1+pi/V2fLI7fPHFFzV06FANGDBAo0aNUkFBgerVq6dHHnlEmzZtqnJ/R44ckSSNHDlSffv2DR5z9H9Ja6OSkhLt2LFDs2bN0qxZs6JeLy4uVp8+fap9ndr+w1QqZWrNNWnSRDk5OdqxY0fUa0fbTjvttCr3O3v2bB06dEgTJ04MfhNScXGxxo8fX/UBG9WpuVNPPVWSKnzvR39vaqtMrblU4T6XetRcedRcalFv5dXFekv6BGHOnDlq06aN5s6dq0gk4tuPzhCtjRs3RrVt2LBBrVu3liS1adNGklS/fn1deumlyR5uyhUXF6ugoEBTp06Nem3u3LmaN2+ennrqKeXl5ZX7/bIqe62uy9SaO+6449ShQ4fgZjXLli1TmzZtEvo2guLiYp133nnB9//000/rpZde8hOEmqq5Fi1aqFmzZsH3vnz5cnXs2DFl106GTK25VOE+l3rUXHnUXGpRb+XVxXpLyRoE6e+bNB21bNkyLV26NHj8/Pnzy33ubPny5Vq2bJkuv/xySVJBQYEKCwv19NNPB/+3Mdauq1X5eqhkO3jwoObOnav+/ftr4MCBUb/uvPNOlZWV+a/4ys/Pl6TgplX5+fnB9srU5HtPp0yuuYEDB2rFihXlflB+7733VFJS4r8qrSq2bt2qt956S4MGDQrW3LBhw1RaWqply5ZJSn7NVeVrTq+99lotWLBAW7du9W1vvvmmNmzYkNB7T6dMrrlk4z6XHtTcV6i51KPevlJX6y2hJwjPPfecfvvb30a133333erfv7/mzp2r733ve+rXr582b96sp556Suecc472798fdU7btm3VrVs33XbbbTp06JCmTJmipk2bavTo0f6YqVOnqlu3burQoYOGDx+uNm3aaNeuXVq6dKm2bdumVatWVTjW5cuXq1evXho7dmzMBR779u3TE088IUn64x//KEl68skn1ahRIzVq1Eh33nmnP3bo0KF6/vnntXnzZj9Dtl577TWVlZXpqquuCr5+0UUX+Y02rr/+enXs2FH16tXTo48+qn379iknJ0e9e/dWQUGBOnXqpF/+8pf6yU9+orZt26qgoEC9e/eu9P2k6r3XhGytudtvv13PPPOM+vXrp5EjR6p+/fqaNGmSmjdvrnvuuafcsYWFhVq8eHG5G7b10ksvyTlXYc1dccUVOv7441VcXKyuXbuqU6dOkqT7779fN9xwg+rXr68rr7xS+fn56tSpk/7whz9o0qRJOu2003TmmWdWuLX8UfPmzdOwYcM0ffr0mAuVx4wZo9mzZ6tXr166++67tX//fk2YMEEdOnTQsGHDKj03HbK15rjPcZ87ipqr2zVHvVFvlarKVx4d/Rqmin5t3brVHTlyxBUVFblWrVq5nJwcd8EFF7gFCxa4IUOGuFatWvm+jn411oQJE9zEiRPdGWec4XJyclz37t3dqlWroq69adMmd/PNN7tTTjnF1a9f37Vo0cL179/fzZkzxx9T3a/GOjqm0K9jx+6cc9dee63Ly8tzH3/8cYX9XXnllS43N9cdOHCgwmOGDh3q6tev7/bs2eOcc+6ZZ55xbdq0cfXq1Sv3Xnbu3On69evnGjRo4CT5r8mq7OvKUvXe0ynba84557Zu3eoGDhzoGjZs6E466STXv39///Wkx+rUqZM75ZRTKu2rQ4cOrmXLlpUeU1hY6AoKCtwXX3zhnHPu4Ycfdi1atHDHHXdcua9EW79+vevRo4fLy8tzkvxXnh79mtPdu3dH9R3v15wetXr1atenTx934oknukaNGrkbb7zR7dy5M65zUyXba477HPe5Y1Fzda/mqLevUG8VizhXyX9HokLNmzfXzTffrAkTJtT0UFAHlJWVqUmTJpoyZYruuOOOmh4O6gjuc0g3ag7pRL1VjAlCAtasWaNvf/vbev/99/W1r32tpoeDOuD111/XHXfcoQ0bNvjvpgZSifsc0o2aQzpRb5VjggAAAADAS8lGaQAAAAAyExMEAAAAAB4TBAAAAAAeEwQAAAAAXkIbpR0VibRJ1jhQCzn3fk0PIQo1l92oOaRbbas56i271bZ6k6i5bJdozfEEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgHd8TQ8AAACgQmea/IjJ3zP5/EAf7yVvOEBdwBMEAAAAAB4TBAAAAAAeEwQAAAAAHmsQAABA7fDtQNtvTd5t8lSTdyVvOEBdxRMEAAAAAB4TBAAAAAAeEwQAAAAAHmsQgDT5J5P7Bo75psnfiKPf/zX5SpM/iaMPIKVODLQtMvk0k78TOOf/kjIa1CZXmDwncMxTJt9v8sHkDQfA3/EEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHImUgSZqa/KzJdvHw3kAfS022azJ7Bs7pFqOPcwPnAHE7NdDWLMY5H5vcK3BMJ5PfM/nDGNdAZmpr8ismLw6cc4/JLnnDARDGEwQAAAAAHhMEAAAAAB4TBAAAAAAeaxCq498CbSeY3N7kG+Pod73J58U9ItSg35rc2uSfmzwh0If96LYV2jhtuclnmfyAyQ/HuAayiL13/ChwTKsYfdiCkqSWMc75mcnnBI6JmLzdZHsvRebJCbQ9Y/K7Jg8KnMOaA1RHY5OvN3lM4By7caNl/2F9pEojygg8QQAAAADgMUEAAAAA4DFBAAAAAOCxBuGoHoE2+/ld+yX03wucYz9Xa8XzWcp2Jq8xmS+2r3GXBtouMNl+vXfoY45VZb8qXpKmmPzvJg8zmTUIdYjdf+AHCfRxKND2osmXmHxvHP3ae+EMkz+Kow/UbqGbTVeT7b93ZSkaC+qGiwJtk0y+0OTQz2WxflZ7yGRbx5J0S4w+ajmeIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwsmOR8imBtpdNbhOjj5MDbfkm2wXIfwqc860Y14mHnbbZcaDG1Q+0lZo8Kx0DkTTHZLtIOdfkBoE+WBeYJcaaPCqOc543ebfJjwXO2WPyN03+b5O/FujDXscWMjKP3dzunwLHLDLZbpAHVEVTk38VOMZuWGvvPfMD5/za5JtNvs7k0OJo+4PCF4FjajGeIAAAAADwmCAAAAAA8JggAAAAAPAycw2C3ZTnmcAxZ6TguueYbD+HK0V/1vY0k6ebfHoc110bxzFIq5JAm90o7WA6BqLwPlbHam7y9wPHPJ2ksaCG2fVKeSb/X+Cc+03eGcd1vm6y3QWwmcmfBvoYb3KsQkbtN9rkkwLH2HoDqsOuFbDrDSTpdyb3S+A6dpGh3S019LOcHctfErhuDeIJAgAAAACPCQIAAAAAjwkCAAAAAC8z1yDYzzkmst7Aft71x4Fjlpm8IY5+PzL5bpPjWXOwxeSb4jgHaVWbPi79vsl2yYpdOtMuhWNBDbN7CVxucujzuT8z+XaTQ3vETDLZfqbX3gd/Gujjl4E2ZLY+Jv8xcMzb6RgI6ox4FvvZdQqp8EmgLbRONYPwBAEAAACAxwQBAAAAgMcEAQAAAICXGWsQLjP5ogT6+KvJ9nP9SxLoMx7xrDmw7OflPkzGQJCtDpv8RY2MArXCOyYvNTm0BsHuK2Pvt5MD57SMMQ67x8GTMY5HZupmsv23+fwkXaenybtNZq+guisSI0vSxybnmGz3dZGkoSZ3MtnuFxPaYOhvgbYMwhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAF5mLFK+x+QT4zjHLjq2i+aSsSi5UaDNbkzUI0YfoXG8kdBoUEedYHJujOPLUjUQ1LzPTQ5t3mOdavKrJocW/TmT/8Pk+XFcF5nvRpPXmWx3cQwZYvLEwDGNTbY7VY40eVoc10V2ONdke2+SpH8z2f5MaRcgh9xgsr1PZiGeIAAAAADwmCAAAAAA8JggAAAAAPAyYw3Cr0z+msn7AufYTSt2JW843g8DbQ/HOGeNyYMCx6RirMharU3+Rozjf5vANZoG2r5p8rdNnm3yhgSui2r6vxT1a9dJPWbythRdF7XLLSbbf3ftmhhJqm/yWJNvDZzz3yZfYfJ0kzfF0Qeyg91ItkHgmM4m23VVoXULn5pcBzfj4wkCAAAAAI8JAgAAAACPCQIAAAAALzPWIMyNkdOlv8kPxnHOYZOfNpn1BqiE3ePg9MAx36lin08F2v5k8rdMbhI45wyT7f4KbU0eFmNcSAL7Xz7dTQ7taRDL64G2qxLoB5nvHJPtTxD237sQe3Oxi6Li+X75V0zuZvJ9gXNYg5CdzjO5a+AY+w/nf8bRr/050+7xUQfwBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAlxmLlGuL+SaHNtew7jL5meQMBTUrN9BWYHInk+3aqd5xXCfPZLtGMBHnBtpOjnHOc4E2u3bV7lezJd4BIXlmmXyNyfHcs6xEzkF2OiXG6+/F0YfdLPTfExzLsX5p8rtJ6BOZaVmg7UAC/RRVdyCZjycIAAAAADwmCAAAAAA8JggAAAAAPNYgVOanJtvp1JE4+licpLEgrewag3EmXxk45+wkXPcTk/ebHNqHKNZf4mdNDm2U9naMPlALnBpos7vPXWuyXT/w50Afq2L0aRfXABXZFscx9qaWruui7rKbqSXys1wdxBMEAAAAAB4TBAAAAAAeEwQAAAAAHmsQjqofaLvAZPs5tdD3g99t8saER4QaNN/ky0w+FDjH7guw2eRfx9HHFpO3m7wucM5ZJr9v8r+ZnMhXQqMWuCTQ9lCMc+x3zD8ZOGaAyXYNwtoY10DdEYmRa0pPk8tqZBSorQ6abH+WWxQ45/PUDCWT8AQBAAAAgMcEAQAAAIDHBAEAAACAV3fXIOSZ/E+BY+wHz62XA23FJofWKaDW62OyXU9gv25ekt5JwnXrmfwzk08PnPOByYNMZs1BhrKfq348jnOuMvkPJp8SOOfBGH1uieO6qBvsv2c19e+b/cnlhybPTNdAUOuENiT6gcm7Tf5l4Jz/S85wMhlPEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4dWeR8kkmP2PywDj6GGFyaNMhFiVnBfvHuNfkd5NwjZxA22yT+5kc2lztBpPfTnhEqFXslyScHDhmscl2tz57h+8f6MP2aze/2hM4B3WT3TRvh8n2yz6eStJ1bR3bRaWtTR6SpOui9mto8m8Dx7Qw+ccmv5q84WQTniAAAAAA8JggAAAAAPCYIAAAAADw6s4aBLvDVDxrDjaZ/ESSxoJab4PJHU3+VeCcpiavMvl9k0cF+viGyctMvj1wzjuBNmSBeDalsm32jj7A5F8E+vjY5GdNDm0ihLppp8lFJk+Mow+7mejXTT4/cM4Ykz8z2e5s+WEc40B2+LnJdr2BJM0yeVKKxpJleIIAAAAAwGOCAAAAAMBjggAAAADAy941CPbD3P8W43j7oXNJujxJY0HGaW/yQyaPDJxjZ9vfjXGN1wJt95j83zH6QBZrFscxu03+vcnd4+hjmMkL4jgHkKRpMV4PrUkI7R90rLJA2+Mm/8TkL2L0iexxicl2742DgXPsBkOIC08QAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHjZu0j5AZOvj3F8aOHUX5M0FmS8B2NkIOnWxXGM3fAxYvJHJk8N9PGHuEcEVM4uWo61iBmIpZXJ/xnj+CGBttA3giAmniAAAAAA8JggAAAAAPCYIAAAAADwsmMNwjmBtoYxzvmVyW8maSwAkAzPm3xC4Bi71mqlyfazt1OqMyAASKHcQJvdlfRkk181eV7yhlPX8QQBAAAAgMcEAQAAAIDHBAEAAACAlx1rEG4OtF1u8v+Z/AuTNyRvOABQbXtNnhA4JtQGAJloWKDtNpOXmhz6+Q9JwRMEAAAAAB4TBAAAAAAeEwQAAAAAXnasQfhdoO0ek//NZNYcAAAA1IwuJo8JHPMTk58x+fPkDQfl8QQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgJcdi5RLAm310z4KAAAAxGOFyWfUyChQAZ4gAAAAAPCYIAAAAADwmCAAAAAA8CLOOVfTgwAAAABQO/AEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgFdjE4QtW7YoEonoscceS1qfixYtUiQS0aJFi5LWJ7IHNYd0o+aQbtQc0o2ay05VmiDMmDFDkUhEK1euTNV4atz27ds1aNAgNWrUSA0bNtTVV1+t999/Pyl9jx49WpFIRNdff33w9SVLlmjcuHHau3dv1GtFRUWaP39+UsZRkXXr1um73/2uTjrpJDVp0kQ33XSTdu/endJrxkLNVQ81V3XZXnPvvfeeRowYoYsvvli5ubmKRCLasmVL0vqfNm2aIpGIunbtGnx97dq1GjduXPCa06ZN04wZM5I2FivV7z1R2V5zEvc57nPpR81Vr+b4iNEx9u/fr169emnx4sUaM2aMxo8fr7fffls9e/bUhx9+WK2+nXN6+eWX1bp1a/3mN79RWVlZ1DFLlizR+PHja6Sgtm3bph49eqi0tFRFRUUaOXKkXn/9dV122WX6/PPPU3bduo6ao+bSbenSpXr88cdVVlam9u3bJ73/4uJitW7dWsuXL1dpaWnU62vXrtX48eNrZIKQ6veOMO5z3OfSjZqrfs0xQTjGtGnTtHHjRi1YsECjR4/WiBEj9Lvf/U47duzQxIkTq9X3okWLtG3bNj333HM6fPiw5s6dm6RRRztw4ECVzykqKtKBAwdUUlKiu+66S2PGjNErr7yiVatWpfQf7LqOmqPm0u2qq67S3r179e677+rGG29Mat+bN2/WkiVLNGnSJDVr1kzFxcVJ7f9YidRcKt87KsZ9jvtculFzSag5VwXTp093ktyKFSsqPObQoUPugQcecN/61rdcw4YN3Yknnui6devmSkpKyh23efNmJ8lNmDDBTZo0ybVs2dLl5ua6Hj16uHfffTeq33Xr1rlrr73WNW7c2OXk5LhOnTq5X//61+WOWbhwoZPkFi5c6NsOHDjg1q1b53bv3h3z/XXp0sV16dIlqr1Pnz7u61//eszzK/ODH/zAnXPOOc455y6//HJ32WWXlXt97NixTlLUr6O/T/bXkCFDyp23Zs0aN3jwYNeoUSPXsWNH55xze/fudevWrXN79+6NOb6CggJ33XXXRbWfddZZ7pJLLqnWe68Oai5x1Fxisr3mjjVhwgT/Z54MDz/8sGvcuLE7dOiQu+2221y7du3KvX7099b+WrhwoWvVqlVUe8+ePcudt2jRInfbbbe5Zs2auUaNGjnnas97r45srznuc9znjkXNZUbNJf0JwieffKJnn31WhYWFevTRRzVu3Djt3r1bffv21TvvvBN1/AsvvKDHH39cd9xxh+677z6tXr1avXv31q5du/wxa9as0UUXXaR169bp3nvv1cSJE5Wfn68BAwZo3rx5lY5n+fLlat++vZ588slKjzty5Ij+8pe/qHPnzlGvXXjhhdq0aVPwMVI8Dh06pFdffVWDBw+WJA0ePFglJSXauXOnP+aaa67xr0+ePFkzZ87UzJkz1axZM82cOVM5OTnq3r27b7/11lvLXeO6667Tp59+qqKiIg0fPlySNG/ePLVv3z7m79H27dv1wQcfVPje33777YTed7pQc9GoudTK1JpLteLiYl1zzTU64YQTNHjwYG3cuFErVqzwr/fo0UN33XWXJGnMmDG+ttq3b68pU6bo9NNP19lnn+3b77///nL933777Vq7dq0efPBB3XvvvZJqz3tPtUytOe5z3OeouQytubinEi6+Gefhw4fdoUOHyrV9/PHHrnnz5u6WW27xbUdnUnl5eW7btm2+fdmyZU6SGzFihG+75JJLXIcOHdxnn33m244cOeIuvvjicv9DFZpxHm0bO3Zspe9t9+7dTpJ76KGHol6bOnWqk+TWr19faR8VmTNnjpPkNm7c6Jxz7pNPPnG5ublu8uTJ5Y6r7H+08vPz/SzzWEdnnIMHD4567eif1/Tp0ysd34oVK5wk98ILL0S9NmrUKCep3O99OlFz1Fy6ZXPNWcn8X/SVK1c6Se73v/+9H/vpp5/u7r777nLHzZ49O2r8R5177rn+qcGxjv6ZdOvWzR0+fLjca7XhvVdXNtcc9znuc9RceZlSc0l/glCvXj2dcMIJkv4+i/voo490+PBhde7cWX/+85+jjh8wYIBatGjh84UXXqiuXbvqjTfekCR99NFHKikp0aBBg1RWVqY9e/Zoz549+vDDD9W3b19t3LhR27dvr3A8hYWFcs5p3LhxlY774MGDkqScnJyo13Jzc8sdU1XFxcXq3Lmz2rZtK0lq0KCB+vXrl9TP5/7whz+Mahs6dKiccxo6dGil56byvacDNReNmkutTK25VCouLlbz5s3Vq1cvSfLf8DFr1ix9+eWXSbnG8OHDVa9evXJtteG9p0Om1hz3Oe5z1FzV1JaaS8ki5eeff17nn3++cnNz1bRpUzVr1kyvv/669u3bF3Vsu3btotrOOuss/w0XpaWlcs7pgQceULNmzcr9Gjt2rCTpgw8+qPaY8/LyJP398ZH12WeflTumKvbu3as33nhDPXv2VGlpqf/1ne98RytXrtSGDRuqN/B/OPPMMxM+N1XvPZ2oua9Qc+mRiTWXKl9++aVmzZqlXr16afPmzb7munbtql27dunNN99MynWqU3PZIBNrjvsc9zlqrmpqS80dn/AoKvDiiy9q6NChGjBggEaNGqWCggLVq1dPjzzyiDZt2lTl/o4cOSJJGjlypPr27Rs85uhMrjqaNGminJwc7dixI+q1o22nnXZalfudPXu2Dh06pIkTJwZXzhcXF2v8+PFVH7BRnZvMqaeeKkkVvvejvze1FTVXHjWXeplac6lSUlKiHTt2aNasWZo1a1bU68XFxerTp0+1r1Pbf5hKpUytOe5z3OeOoubiU1tqLukThDlz5qhNmzaaO3euIpGIbz86O7Q2btwY1bZhwwa1bt1aktSmTRtJUv369XXppZcme7jecccdpw4dOgQ3DVm2bJnatGmjBg0aVLnf4uJinXfeecH3//TTT+ull17yBXXs75dV2WvV1aJFCzVr1iz43pcvX66OHTum7NrJQM2VR82lXqbWXKoUFxeroKBAU6dOjXpt7ty5mjdvnp566inl5eXVWM1lukytOe5z3OeoufIypeZSsgZBkpxzvm3ZsmVaunRp8Pj58+eX+8zZ8uXLtWzZMl1++eWSpIKCAhUWFurpp58Ozohi7Qz36aefav369dqzZ0/MsQ8cOFArVqwo9xv73nvvqaSkRNddd13M862tW7fqrbfe0qBBgzRw4MCoX8OGDVNpaamWLVsmScrPz5ek4MYa+fn5wfbK7Nu3T+vXrw8+CrSuvfZaLViwQFu3bvVtb775pjZs2JDQe08nau4r1Fx6ZHLNJdvBgwc1d+5c9e/fP1hzd955p8rKyvTaa69JSn7N1eR7T6dMrjnuc9znJGruqEypuYSeIDz33HP67W9/G9V+9913q3///po7d66+973vqV+/ftq8ebOeeuopnXPOOdq/f3/UOW3btlW3bt1022236dChQ5oyZYqaNm2q0aNH+2OmTp2qbt26qUOHDho+fLjatGmjXbt2aenSpdq2bZtWrVpV4ViXL1+uXr16aezYsTEXttx+++165pln1K9fP40cOVL169fXpEmT1Lx5c91zzz3lji0sLNTixYvL/cWxXnrpJTnndNVVVwVfv+KKK3T88ceruLhYXbt2VadOnSRJ999/v2644QbVr19fV155pfLz89WpUyf94Q9/0KRJk3TaaafpzDPPVNeuXSt9P/PmzdOwYcM0ffr0mAtbxowZo9mzZ6tXr166++67tX//fk2YMEEdOnTQsGHDKj03Hag5ai7dsrXm9u3bpyeeeEKS9Mc//lGS9OSTT6pRo0Zq1KiR7rzzTn/s0KFD9fzzz2vz5s3+fwGt1157TWVlZRXW3EUXXeQ3Tbv++uvVsWNH1atXT48++qj27dunnJwc9e7dWwUFBerUqZN++ctf6ic/+Ynatm2rgoIC9e7du9L3k6r3XhOytea4z3GfO4qay6Cai+u7jv6hok1ujv7aunWrO3LkiCsqKnKtWrVyOTk57oILLnALFixwQ4YMca1atfJ9HbuxxsSJE90ZZ5zhcnJyXPfu3d2qVauirr1p0yZ38803u1NOOcXVr1/ftWjRwvXv39/NmTPHH5OMr//bunWrGzhwoGvYsKE76aSTXP/+/f3XWR2rU6dO7pRTTqm0rw4dOriWLVtWekxhYaErKChwX3zxhXPu7xsNtWjRwh133HHlviJr/fr1rkePHi4vLy+4sUZo45B4vxbrqNWrV7s+ffq4E0880TVq1MjdeOONbufOnXGdmyrU3FeoufTI9pqraLMeSeXG7pxz1157rcvLy3Mff/xxhf1deeWVLjc31x04cKDCY4YOHerq16/v9uzZ45xz7plnnnFt2rRx9erVK/dedu7c6fr16+caNGjgpOiN0kJfyZiq955O2V5zznGf4z73FWouM2ou4lwlUyYElZWVqUmTJpoyZYruuOOOmh4O6gBqDjWhefPmuvnmmzVhwoSaHgrqAO5zSDdqrmIp+ZrTbPfWW2+pRYsWfoc7INWoOaTbmjVrdPDgQf34xz+u6aGgjuA+h3Sj5irGEwQAAAAAHk8QAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHgJbZR2VCTSJlnjQC3k3Ps1PYQo1Fx2o+aQbrWt5qi37Fbb6k2i5rJdojXHEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAADe8TU9AAAAAKAmvBRou8jkwSYvS9FYahOeIAAAAADwmCAAAAAA8JggAAAAAPBYg5Bi7Ux+yuQbA+fsTNFYUDf0NPlNk0P/K1Bo8ltJGw0AALVXq0Bba5NnmnyuyV8kbTS1B08QAAAAAHhMEAAAAAB4TBAAAAAAeGlfg3BSjLwvcM7BFI0lHa4wuYfJ/xw45xGTv0zecJCFhpj8I5OPxNHHJJNfMHlq4BzqEkBtcK/JPw0c83OT70vRWFD7nWFy5zjOaWuy/eGZNQgAAAAAshoTBAAAAAAeEwQAAAAAHhMEAAAAAF7aFyn/2GS7uGhU4JwpqRlKWvwpxutjA20vm7wpSWNB5rMLkiXpJpPPT6Bfe85jJs8PnPPXBK6DDNQy0DbC5NtNtv+yzAr0EdolEoiD/XIT+8UMLnDOv5q80eTnqjMgZJRGJteP45z5Jh9KykhqN54gAAAAAPCYIAAAAADwmCAAAAAA8NK+BiGW0Gfy3zf5tXQMJEma1/QAUGudHGjraPJ0k5sFzsmJcZ31Jof+V+CsGH2gDhlm8uTAMfYD3LeabHciCt3YHzL5vRjjQp1Vz+TbTI7n39ldJi9NfDjIMPYHXbsWNh52bWg8G5BmOp4gAAAAAPCYIAAAAADwmCAAAAAA8GrdGgT7/cZS9Oew+5gca6+BdMo3+d8S6GOQyY8kOBbULlebPDxwjK1tO4NP5HOPE2L0KUnPJNAvMlDoC7/vMflBkycFzrFFtc/kC0wOrUEoC7QBAd82OZF/E+26hXUJjgWZx97Cvl8jo8g8PEEAAAAA4DFBAAAAAOAxQQAAAADgMUEAAAAA4KV9kfLmBM5paPJ4k/8pcM7eBK6TDO1MvrBGRoHa4EaTn0+gj2TM4CNpug4ygN0ETZJ+YvK/mvxkAtexq+0/CBzztwT6RdZrFWj7RRX7eDPQtjCBsSDzhL784wdpH0V24OcCAAAAAB4TBAAAAAAeEwQAAAAAXtrXIMww+TSTQ/vpWH1NvjZwzH/EO6Ak22Xy+ya3iaOPV5I0FqSXXXMwxWS7ydlngT5s/TQwuUkc47D92v2o7JoeKbEN2JABGpv8cOCYOSb/MoHrtDT5nxPoA5D0m0DbOTHO+cRku4+fFL7fIvPZZVVPBI45weQ/m/yt5A0nq/AEAQAAAIDHBAEAAACAxwQBAAAAgJf2NQj2s86Pm2w/xy1JbWP0eUegbZ7JH8XoI1mamxzPmgNknqsDbXafg1if618WaLvM5CEmPxOjT0kaY7L9u2D7RBapZ/IfTQ7tR3CbyV8mcN0XTbY3vokJ9Ik66dxAm4txzjST/5CksSC5TjL5myZ/I3BOF5MHmWyXWYXcbfIbJm+Mo4+6iCcIAAAAADwmCAAAAAA8JggAAAAAvLSvQbDs9xfbj8xKsdcgdAi0nWFyImsQ6pt8axznXJfAdVD72c/tT4njHPu923bNwV0JjGNVoM2ufYj1Nfb2a+8labjJF8Y9ItQqA00+y+TegXM+TuA6g02+yOT9Jj+WwDVQJ9jlKZHAMXYNwpsmh7b3QO1jfy6z+1XZ21XIPpPturzQrWazyafHcR3wBAEAAADAMZggAAAAAPCYIAAAAADwmCAAAAAA8Gp8kbK1NNCWyMZO3zbZLu60r18c6MNu6vHvCYwjlvWBtkTWDCK1HjA5P45zikz+WQLX/R+T/ytwTGjvq8ocCLQdqmIfqKXszfI9k5ck0Kfd/VGSJpts/6vpCZOrWqTIWk+aPMDk0KZofzHZbqjK/SszrDPZbpTWLo4+7Bfb/DXx4VRJPP/mZxueIAAAAADwmCAAAAAA8JggAAAAAPBq3RoEu3GGJBWabPfoCbGfc7Q5Hnb2dCSBPmJpH2gbYPJzKbguKmc/G9nA5NDMOhV/mTaloM8QuzkR/3OQofqa/KDJh+Powxb7q4FjvmbyUyY/Gsd1kPW6BNoGmHxKHP38yuQ9CY0GtY1dO7I6TdctM3ln4Bhbl1eZPCNpo6m9+DkAAAAAgMcEAQAAAIDHBAEAAACAV+vWIIRMNPmGNF3XrjkIfT9zKlxkMmsQUuvcQJv92HVjk1OxHiVdQt/nfILJmfz+6pTeMV7/dRx99DH5aZNbBs4pNXmMyfZDvqiTbgm0nRrjHPtd+VJ8ZQzE60OTNweOsWsQFqVmKLUaTxAAAAAAeEwQAAAAAHhMEAAAAAB4TBAAAAAAeBmxSLmm2HV4dpHy64Fz9pls9ylC7fN4oC20LjNbDAy0XZj2USApPjD5M5P/02S7CZokNTPZ7l5kd9GTpKkmfxI4BnXO3Sb/IHBMrC/7uCzQtiOx4QBJUxdrkCcIAAAAADwmCAAAAAA8JggAAAAAvDqzBuEjk/9qst2MTZJmJXCdjiazBiE7ja7pAVTBN0z+eRznbDHZfrQdtcRqk39osv0Q+KpAHy+b/KTJKwPn2M3UUCedbvI/mxz6H8gvTX7G5Lr4WW/UPnatjF3uVRfwBAEAAACAxwQBAAAAgMcEAQAAAICXEWsQNpn8gsltAuesM3mayfaju7VJH5Mbmbw3PcNAJT6s6QFUwq45+LXJTQPn2M9X2r0S6uLnLzPSzBg5tKfBZJObm3xt4By7VwLqhK+b/JrJ9t4TYsvt3sSHgzqoncmN4zjnoMn2329bk5L0qMl2uxibTwz08bDJc0y2f39qG54gAAAAAPCYIAAAAADwmCAAAAAA8DJiDUKZyfarvbNNC5NPqJFR1B2hj2XHmjlPD7TZj3unQn6gza7JuTpGH+8H2vqbvCHuESGj9Ai03WnyT00O7YOAOsmuMYhnzYFV2z93jfSxP9vYNS5S9N4at5oc+uy/9bnJ+01uEkcfr5i82+TQz2knm7zT5Nr+d4EnCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAC8jFiknEn2mmwXpZySQJ9FJttFOpL0ZQL94u9+Emj7T5PtYqOQEpOdyXbDsvcCfYw22S6gDi2EutDkT0229TM30AeLkuuIlwJtfzP55+kYCDJRPIs5j7Uo0LY2CeNAZrJ7ME4x+fokXGNHoM3+W7zG5FVJuG487BeK1HY8QQAAAADgMUEAAAAA4DFBAAAAAOCxBiHJtph8rcn289/2M3khQ0y+K3CM/dw54mfXDkjRf26vmhxak2D3oDpicveqDOof7Aze9ilJi022n3NMxwZuqKU6mfy1wDH2hnIgRWNBxnu4isf/MtC2NwnjQGb6vsmJrDl43eSJJv8xcM4XCVwHPEEAAAAAcAwmCAAAAAA8JggAAAAAPNYgpNhykweY/JvAOaGPCR+rc6DtrXgHhLjY389vmvwvgXP+PQXjsPto/L/AMXZfjE9SMA5kiByTf2Xy9sA5LFJBwDmBtvwY54w3ObTnCuqueSYPNdluySJJr5g8PWmjQSw8QQAAAADgMUEAAAAA4DFBAAAAAOAxQQAAAADgsUg5zVaa/G+BY0aabDcGsX0g9eziqXGBY943eZTJ3zB5faCPCSZvMnlJ4BzAG2ayXV3fMXAOuywi4KJAW4MY5xwy2SVpLMgOW0y2tyfULjxBAAAAAOAxQQAAAADgMUEAAAAA4EWccwl/TDASaZPMsaCWcc5+qr7mUXPZjZqrpjUm2w+Fdwmc82WKxpIhalvN1eZ622LyiSb3MfmdlI0kc9W2epNqd82h+hKtOZ4gAAAAAPCYIAAAAADwmCAAAAAA8NgHAQCyRROTHzK5jq83QPW0rukBAEgbniAAAAAA8JggAAAAAPCYIAAAAADwWIMAANni1JoeAAAgG/AEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAxwQBAAAAgMcEAQAAAIDHBAEAAACAF3HOuZoeBAAAAIDagScIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAPCYIAAAAADwmCAAAAAA8JggAAAAAvP8P6HQP3bKFoaAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x800 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attach key attributes to Subset objects for easier access\n",
    "def attach_dataset_attributes(subset):\n",
    "    \"\"\" Attach key attributes from the underlying dataset to a Subset object.\"\"\"\n",
    "    if hasattr(subset, 'dataset'):\n",
    "        for attr in ['INPUT_SHAPE', 'num_labels', 'num_attributes', 'data_type']:\n",
    "            if hasattr(subset.dataset, attr):\n",
    "                setattr(subset, attr, getattr(subset.dataset, attr))\n",
    "\n",
    "\n",
    "# Create a perfectly balanced test dataset (all probabilities set to 0.5)\n",
    "balanced_test_hparams = base_hparams.copy()\n",
    "balanced_test_hparams.update({\n",
    "    'cmnist_label_prob': 0.5,\n",
    "    'cmnist_attr_prob': 0.5,\n",
    "    'cmnist_spur_prob': 0.5,\n",
    "    'cmnist_flip_prob': 0.0\n",
    "})\n",
    "\n",
    "DatasetClass = getattr(datasets, DATASET_NAME)\n",
    "train_dataset = DatasetClass(DATA_PATH, 'tr', base_hparams)\n",
    "val_dataset = DatasetClass(DATA_PATH, 'va', base_hparams)\n",
    "test_dataset = DatasetClass(DATA_PATH, 'te', balanced_test_hparams)\n",
    "\n",
    "# If debug, reduce all datasets to size 100\n",
    "if DEBUG:\n",
    "    train_indices = random.sample(range(len(train_dataset)), min(100, len(train_dataset)))\n",
    "    val_indices = random.sample(range(len(val_dataset)), min(100, len(val_dataset)))\n",
    "    test_indices = random.sample(range(len(test_dataset)), min(100, len(test_dataset)))\n",
    "    train_dataset = Subset(train_dataset, train_indices)\n",
    "    val_dataset = Subset(val_dataset, val_indices)\n",
    "    test_dataset = Subset(test_dataset, test_indices)\n",
    "    dataset_sizes = [10, 100]\n",
    "else:\n",
    "    max_train_size = len(train_dataset)\n",
    "    dataset_sizes = np.logspace(1, np.log10(max_train_size), num=NUM_FIT, dtype=int).tolist()\n",
    "\n",
    "    \n",
    "attach_dataset_attributes(train_dataset)\n",
    "attach_dataset_attributes(val_dataset)\n",
    "attach_dataset_attributes(test_dataset)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "input_shape = train_dataset.INPUT_SHAPE\n",
    "num_labels = train_dataset.num_labels\n",
    "num_attributes = train_dataset.num_attributes\n",
    "data_type = getattr(train_dataset, 'data_type', 'images')\n",
    "\n",
    "print('Datasets:')\n",
    "print(f'  Train size: {len(train_dataset)} | Val size: {len(val_dataset)} | Test size: {len(test_dataset)} (restricted)')\n",
    "print(f'  Input shape: {input_shape} | data_type: {data_type}')\n",
    "print(f'  num_labels: {num_labels} | num_attributes: {num_attributes}')\n",
    "\n",
    "    \n",
    "if USE_STRATIFIED:\n",
    "    group_to_indices = build_group_index(train_dataset)\n",
    "    group_counts_dict = {k: len(v) for k, v in sorted(group_to_indices.items())}\n",
    "    print('Stratified groups (counts):', group_counts_dict)\n",
    "\n",
    "    # Aggregate counts for each class and attribute\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.DataFrame([{'class': k[0], 'attribute': k[1], 'count': v} for k, v in group_counts_dict.items()])\n",
    "    class_counts = df.groupby('class')['count'].sum()\n",
    "    attr_counts = df.groupby('attribute')['count'].sum()\n",
    "    total = df['count'].sum()\n",
    "\n",
    "    print('\\nClass distribution:')\n",
    "    class_dist = df.groupby('class')['count'].sum().to_frame()\n",
    "    class_dist['percentage'] = (class_dist['count'] / total * 100).round(2)\n",
    "    print(class_dist.to_string())\n",
    "\n",
    "    print('\\nAttribute distribution:')\n",
    "    attr_dist = df.groupby('attribute')['count'].sum().to_frame()\n",
    "    attr_dist['percentage'] = (attr_dist['count'] / total * 100).round(2)\n",
    "    print(attr_dist.to_string())\n",
    "\n",
    "    print('\\nGroup (class, attribute) distribution:')\n",
    "    group_dist = df.set_index(['class','attribute'])\n",
    "    group_dist['percentage'] = (group_dist['count'] / total * 100).round(2)\n",
    "    print(group_dist.to_string())\n",
    "    \n",
    "# Preview a few samples (images only)\n",
    "if data_type == 'images':\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(8, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for k, ax in enumerate(axes):\n",
    "        idx, x, y, a, _ = train_dataset[k]\n",
    "        # Scale per-image to [0,1] for visualization\n",
    "        x_vis = x.detach().cpu()\n",
    "        x_min, x_max = x_vis.min(), x_vis.max()\n",
    "        x_vis = (x_vis - x_min) / (x_max - x_min + 1e-6)\n",
    "        ax.imshow(x_vis.permute(1, 2, 0))\n",
    "        ax.set_title(f'Label: {int(y)}, Attr: {int(a)}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Non-image dataset preview omitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1be384",
   "metadata": {},
   "source": [
    "## Training and evaluation\n",
    "\n",
    "Main training loop over dataset sizes and algorithms with robust error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset sizes: [10, 37, 144, 547, 2080, 7899, 30000]\n",
      "\n",
      "--- Training with size=10 ---\n",
      "[Init] size=10 | data_type=images | input_shape=(3, 28, 28) | labels=2 | attrs=2 | stratified=True\n",
      "GPU memory after model creation: 0.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 160\n",
      "[Final] size=10 | train_loss=4561.5406 | val_loss=78693.8678 | test_loss=81493.2373\n",
      "\n",
      "--- Training with size=37 ---\n",
      "[Init] size=37 | data_type=images | input_shape=(3, 28, 28) | labels=2 | attrs=2 | stratified=True\n",
      "GPU memory after model creation: 0.02 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 120\n",
      "[Final] size=37 | train_loss=18141.0273 | val_loss=72408.5201 | test_loss=73659.6827\n",
      "\n",
      "--- Training with size=144 ---\n",
      "[Init] size=144 | data_type=images | input_shape=(3, 28, 28) | labels=2 | attrs=2 | stratified=True\n",
      "GPU memory after model creation: 0.02 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 400\n",
      "[Final] size=144 | train_loss=37416.7668 | val_loss=66747.5196 | test_loss=68939.9374\n",
      "\n",
      "--- Training with size=547 ---\n",
      "[Init] size=547 | data_type=images | input_shape=(3, 28, 28) | labels=2 | attrs=2 | stratified=True\n",
      "GPU memory after model creation: 0.02 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 240\n",
      "[Final] size=547 | train_loss=57762.0266 | val_loss=66970.7026 | test_loss=68357.7061\n",
      "\n",
      "--- Training with size=2080 ---\n",
      "[Init] size=2080 | data_type=images | input_shape=(3, 28, 28) | labels=2 | attrs=2 | stratified=True\n",
      "GPU memory after model creation: 0.02 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train size=2080 | step=980 | train_loss=51258.320 | val_loss=52077.690 | bad_checks=0/3: : 993it [00:31, 36.07it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import gc\n",
    "import torch\n",
    "from source.learning.algorithms import VAE\n",
    "\n",
    "# Use environment variable for timestamp if set, else fallback to current time\n",
    "base_timestamp = os.environ.get('RESULT_FOLDER', time.strftime('%Y%m%d-%H%M%S'))\n",
    "\n",
    "result_dir = os.path.join(\"../results\", base_timestamp)\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "log_file = os.path.join(result_dir, 'training.log')\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Enhanced error tracking\n",
    "ERROR_LOG = {\n",
    "    'size_failures': {},\n",
    "    'step_failures': {},\n",
    "    'validation_failures': {},\n",
    "    'test_failures': {}\n",
    "}\n",
    "\n",
    "# Function to clear GPU memory\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory and run garbage collection\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Function to convert tensor to float (detach from GPU)\n",
    "def tensor_to_float(tensor_val):\n",
    "    \"\"\"Convert tensor to float, detaching from GPU memory\"\"\"\n",
    "    if isinstance(tensor_val, dict):\n",
    "        return {k: tensor_to_float(v) for k, v in tensor_val.items()}\n",
    "    elif hasattr(tensor_val, 'item'):\n",
    "        return tensor_val.detach().cpu().item()\n",
    "    elif hasattr(tensor_val, 'detach'):\n",
    "        return tensor_val.detach().cpu().numpy()\n",
    "    else:\n",
    "        return float(tensor_val)\n",
    "\n",
    "# Precompute subsets for each dataset size\n",
    "subset_indices_map = {}\n",
    "for size in dataset_sizes:\n",
    "    if USE_STRATIFIED:\n",
    "        subset_indices = w(group_to_indices, size, rng=np.random.RandomState(0 + size))\n",
    "        subset_indices_map[size] = subset_indices\n",
    "    else:\n",
    "        subset_indices = random.sample(indices, min(size, len(indices)))\n",
    "        subset_indices_map[size] = subset_indices\n",
    "\n",
    "# Initialize tracking\n",
    "hparams = base_hparams.copy()\n",
    "\n",
    "val_loss_map = [float('nan')] * len(dataset_sizes)\n",
    "train_loss_map = [float('nan')] * len(dataset_sizes)\n",
    "test_loss_map = [float('nan')] * len(dataset_sizes)\n",
    "\n",
    "print(f\"Training on dataset sizes: {dataset_sizes}\")\n",
    "\n",
    "for idx, size in enumerate(dataset_sizes):\n",
    "    print(f\"\\n--- Training with size={size} ---\")\n",
    "    \n",
    "\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    subset_indices = subset_indices_map[size]\n",
    "    train_subset = Subset(train_dataset, subset_indices)\n",
    "    attach_dataset_attributes(train_subset)\n",
    "\n",
    "    input_shape = train_subset.INPUT_SHAPE\n",
    "    num_labels = train_subset.num_labels\n",
    "    num_attributes = train_subset.num_attributes\n",
    "    data_type = getattr(train_subset, 'data_type', 'images')\n",
    "    hparams = hparams_registry.default_hparams(\"VAE\", DATASET_NAME)\n",
    "    hparams.update(base_hparams)\n",
    "    \n",
    "    learner = VAE(data_type, input_shape, num_labels, num_attributes, len(train_subset), hparams)\n",
    "    if hasattr(learner, 'to'):\n",
    "        learner = learner.to(DEVICE)\n",
    "\n",
    "    print(f\"[Init] size={size} | data_type={data_type} | input_shape={input_shape} | labels={num_labels} | attrs={num_attributes} | stratified={USE_STRATIFIED}\")\n",
    "    print(f\"GPU memory after model creation: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "    checkpoint_freq = max(20, math.ceil(len(train_subset) / BATCH_SIZE))\n",
    "    best_val = float('inf')\n",
    "    bad_checks = 0\n",
    "\n",
    "    # Include spur_prob in checkpoint names\n",
    "    spur_prob_str = str(cmnist_spur_prob).replace('.', 'p')\n",
    "    \n",
    "    # Get the root timestamp directory for saving checkpoints\n",
    "    timestamp_root = find_timestamp_root(result_dir)\n",
    "    featurizer_path = os.path.join(timestamp_root, 'checkpoints', f'featurizer_size{size}_spur{spur_prob_str}.pt')\n",
    "    os.makedirs(os.path.dirname(featurizer_path), exist_ok=True)\n",
    "    vae_path = os.path.join(timestamp_root, 'checkpoints', 'VAE', f'vae_size{size}_spur{spur_prob_str}.pt')\n",
    "    os.makedirs(os.path.dirname(vae_path), exist_ok=True)\n",
    "    train_losses_epoch = []\n",
    "    learner.train()\n",
    "\n",
    "    train_minibatches_iterator = iter(InfiniteDataLoader(\n",
    "        train_subset, None, BATCH_SIZE, NUM_WORKERS\n",
    "    ))\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    pbar = tqdm(itertools.count(), desc=f\"Train size={size}\", leave=False)\n",
    "    for step in pbar:\n",
    "        try:\n",
    "            # Get next training batch - now includes digit value\n",
    "            i, x, y, a, digit = next(train_minibatches_iterator)\n",
    "            x, y, a = x.to(DEVICE), y.to(DEVICE), a.to(DEVICE)\n",
    "\n",
    "            cur_loss = learner.update((i, x, y, a), step)\n",
    "            \n",
    "            # Convert loss to float immediately to free GPU memory\n",
    "            cur_loss_float = tensor_to_float(cur_loss)\n",
    "            train_losses_epoch.append(cur_loss_float)\n",
    "            \n",
    "            do_check = (\n",
    "                step > 0 and\n",
    "                (step % checkpoint_freq == 0 or step == 1000)  # Check at regular intervals\n",
    "            )\n",
    "            \n",
    "            if do_check:\n",
    "                # Compute validation loss - now handles digit value\n",
    "                learner.eval()\n",
    "                val_losses_step = []\n",
    "                \n",
    "                with torch.no_grad():  # Important: disable gradients during validation\n",
    "                    for i_val, x_val, y_val, a_val, digit_val in val_loader:\n",
    "                        x_val, y_val = x_val.to(DEVICE), y_val.to(DEVICE)\n",
    "                        _, loss = learner.predict(x_val, y_val, return_loss=True)\n",
    "                        # Convert to float immediately and move to CPU\n",
    "                        val_losses_step.append(tensor_to_float(loss))\n",
    "                        \n",
    "                learner.train()\n",
    "                \n",
    "                mean_val_loss = sum(val_losses_step) / len(val_losses_step)\n",
    "                \n",
    "                improved = mean_val_loss < (best_val - ES_MIN_DELTA)\n",
    "                if improved:\n",
    "                    best_val = mean_val_loss\n",
    "                    bad_checks = 0\n",
    "                    torch.save(learner.featurizer.state_dict(), featurizer_path)\n",
    "                    torch.save(learner.state_dict(), vae_path)\n",
    "                else:\n",
    "                    bad_checks += 1\n",
    "\n",
    "                # Extract loss value from dictionary for display\n",
    "                cur_loss_val = cur_loss_float.get(\"loss\", 0.0) if isinstance(cur_loss_float, dict) else cur_loss_float\n",
    "                pbar.set_description(f\"Train size={size} | step={step} | train_loss={cur_loss_val:.3f} | val_loss={mean_val_loss:.3f} | bad_checks={bad_checks}/{ES_PATIENCE}\")\n",
    "                \n",
    "                # Clear validation losses from memory\n",
    "                del val_losses_step\n",
    "                \n",
    "                if bad_checks >= ES_PATIENCE:\n",
    "                    print(f\"Early stopping at step {step}\")\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            if ROBUST_TRAINING:\n",
    "                print(f\"Error at step {step}: {e}\")\n",
    "                ERROR_LOG['step_failures'][f'size_{size}_step_{step}'] = str(e)\n",
    "                if CONTINUE_ON_ERROR:\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    # Load best model and compute final metrics\n",
    "    try:\n",
    "        learner.load_state_dict(torch.load(vae_path))\n",
    "        learner.eval()\n",
    "        \n",
    "        # Validation loss\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i_val, x_val, y_val, a_val, digit_val in val_loader:\n",
    "                x_val, y_val, a_val = x_val.to(DEVICE), y_val.to(DEVICE), a_val.to(DEVICE)\n",
    "                _, loss = learner.predict(x_val, y_val, return_loss=True)\n",
    "                val_losses.append(tensor_to_float(loss))\n",
    "        val_loss = sum(val_losses) / len(val_losses)\n",
    "        val_loss_map[idx] = val_loss\n",
    "        del val_losses  # Clear from memory\n",
    "        \n",
    "        # Test loss  \n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        test_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i_test, x_test, y_test, a_test, digit_test in test_loader:\n",
    "                x_test, y_test, a_test = x_test.to(DEVICE), y_test.to(DEVICE), a_test.to(DEVICE)\n",
    "                _, loss = learner.predict(x_test, y_test, return_loss=True)\n",
    "                test_losses.append(tensor_to_float(loss))\n",
    "        test_loss = sum(test_losses) / len(test_losses)\n",
    "        test_loss_map[idx] = test_loss\n",
    "        del test_losses  # Clear from memory\n",
    "        \n",
    "        # Training loss (from last epoch) - now working with floats\n",
    "        recent_losses = train_losses_epoch[-min(len(train_losses_epoch), 10):]\n",
    "        if isinstance(recent_losses[0], dict):\n",
    "            train_loss_map[idx] = sum([loss.get(\"loss\", 0.0) for loss in recent_losses]) / len(recent_losses)\n",
    "        else:\n",
    "            train_loss_map[idx] = sum(recent_losses) / len(recent_losses)\n",
    "        \n",
    "        print(f\"[Final] size={size} | train_loss={train_loss_map[idx]:.4f} | val_loss={val_loss:.4f} | test_loss={test_loss:.4f}\")\n",
    "        logger.info(f\"Completed size={size} | train_loss={train_loss_map[idx]:.4f} | val_loss={val_loss:.4f} | test_loss={test_loss:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        if ROBUST_TRAINING:\n",
    "            print(f\"Error in evaluation for size {size}: {e}\")\n",
    "            ERROR_LOG['validation_failures'][f'size_{size}'] = str(e)\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Checkpoint Analysis: PCA and UMAP Visualization Function\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from source.learning.algorithms import VAE\n",
    "\n",
    "def analyze_checkpoints_folder(checkpoint_folder, eval_dataset, comparison_name=\"Checkpoint Comparison\"):\n",
    "    \"\"\"\n",
    "    Load multiple VAE checkpoints and generate PCA and UMAP visualizations for each.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_folder (str): Path to folder containing .pt checkpoint files\n",
    "        eval_dataset: Dataset to extract embeddings from\n",
    "        comparison_name (str): Name for the comparison plots\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all .pt files in the folder\n",
    "    checkpoint_files = glob.glob(os.path.join(checkpoint_folder, \"*.pt\"))\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        print(f\"No .pt checkpoint files found in {checkpoint_folder}\")\n",
    "        return\n",
    "    \n",
    "    # Sort checkpoints by training size (extract number from filename like vae_size547.pt)\n",
    "    def extract_size_from_filename(filepath):\n",
    "        filename = os.path.basename(filepath)\n",
    "        # Look for pattern like \"size123\" in filename\n",
    "        import re\n",
    "        match = re.search(r'size(\\d+)', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            # Fallback to alphabetical sorting if no size found\n",
    "            return 0\n",
    "    \n",
    "    checkpoint_files.sort(key=extract_size_from_filename)\n",
    "    print(f\"Found {len(checkpoint_files)} checkpoint files (sorted by training size):\")\n",
    "    for i, file in enumerate(checkpoint_files):\n",
    "        size = extract_size_from_filename(file)\n",
    "        print(f\"  {i+1}: {os.path.basename(file)} (size: {size})\")\n",
    "    \n",
    "    # Prepare evaluation dataset\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    # Store results for all checkpoints\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    all_attrs = []\n",
    "    all_digits = []\n",
    "    all_reconstructions = []  # Store reconstructions for visualization\n",
    "    all_original_samples = []  # Store original samples for reconstruction comparison\n",
    "    checkpoint_names = []\n",
    "    \n",
    "    for checkpoint_path in checkpoint_files:\n",
    "        checkpoint_name = os.path.basename(checkpoint_path).replace('.pt', '')\n",
    "        training_size = extract_size_from_filename(checkpoint_path)\n",
    "        display_name = f\"Size {training_size}\" if training_size > 0 else checkpoint_name\n",
    "        checkpoint_names.append(display_name)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Create a new learner instance (using correct parameter names)\n",
    "            # Get the current hyperparameters to use\n",
    "            current_hparams = hparams if 'hparams' in globals() else base_hparams\n",
    "            \n",
    "            temp_learner = VAE(\n",
    "                data_type=getattr(eval_dataset, 'data_type', 'images'),\n",
    "                input_shape=eval_dataset.INPUT_SHAPE,\n",
    "                num_classes=eval_dataset.num_labels,  # VAE expects num_classes, not num_labels\n",
    "                num_attributes=eval_dataset.num_attributes,\n",
    "                num_examples=len(eval_dataset),\n",
    "                hparams=current_hparams\n",
    "            )\n",
    "            \n",
    "            # Load checkpoint\n",
    "            temp_learner.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
    "            temp_learner = temp_learner.to(DEVICE)\n",
    "            temp_learner.eval()\n",
    "            \n",
    "            # Extract embeddings\n",
    "            embeddings_list = []\n",
    "            labels_list = []\n",
    "            attrs_list = []\n",
    "            digits_list = []\n",
    "            \n",
    "            # Get 3 samples for reconstruction visualization\n",
    "            sample_originals = []\n",
    "            sample_reconstructions = []\n",
    "            sample_labels = []\n",
    "            sample_attrs = []\n",
    "            sample_digits = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (i_batch, x_batch, y_batch, a_batch, digit_batch) in enumerate(eval_loader):\n",
    "                    x_batch = x_batch.to(DEVICE)\n",
    "                    \n",
    "                    features = temp_learner.featurizer(x_batch)\n",
    "\n",
    "                    # Move to CPU and convert to numpy\n",
    "                    embeddings_list.append(features.cpu().numpy())\n",
    "                    labels_list.append(y_batch.numpy())\n",
    "                    attrs_list.append(a_batch.numpy())\n",
    "                    digits_list.append(digit_batch.numpy())\n",
    "                    \n",
    "                    # Collect first 3 samples for reconstruction visualization\n",
    "                    if batch_idx == 0 and len(sample_originals) < 3:\n",
    "                        # Get reconstructions for the first 3 samples\n",
    "                        n_samples_to_get = min(3, len(x_batch))\n",
    "                        x_samples = x_batch[:n_samples_to_get]\n",
    "                        \n",
    "                        # Encode and decode\n",
    "                        mu, logvar = temp_learner.encode(x_samples)\n",
    "                        reconstructed = temp_learner.decode(mu)  # Use mean reconstruction\n",
    "                        \n",
    "                        # Store samples\n",
    "                        sample_originals.extend([x_samples[i].cpu() for i in range(n_samples_to_get)])\n",
    "                        sample_reconstructions.extend([reconstructed[i].cpu() for i in range(n_samples_to_get)])\n",
    "                        sample_labels.extend([y_batch[i].item() for i in range(n_samples_to_get)])\n",
    "                        sample_attrs.extend([a_batch[i].item() for i in range(n_samples_to_get)])\n",
    "                        sample_digits.extend([digit_batch[i].item() for i in range(n_samples_to_get)])\n",
    "            \n",
    "            # Concatenate all batches\n",
    "            embeddings = np.concatenate(embeddings_list, axis=0)\n",
    "            labels = np.concatenate(labels_list, axis=0)\n",
    "            attrs = np.concatenate(attrs_list, axis=0)\n",
    "            digits = np.concatenate(digits_list, axis=0)\n",
    "            \n",
    "            all_embeddings.append(embeddings)\n",
    "            all_labels.append(labels)\n",
    "            all_attrs.append(attrs)\n",
    "            all_digits.append(digits)\n",
    "            all_reconstructions.append(sample_reconstructions)\n",
    "            all_original_samples.append(sample_originals)\n",
    "            \n",
    "\n",
    "            # Clean up\n",
    "            del temp_learner\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {checkpoint_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_embeddings:\n",
    "        print(\"No checkpoints were successfully processed.\")\n",
    "        return\n",
    "    \n",
    "    # Create comparison plots\n",
    "    n_checkpoints = len(all_embeddings)\n",
    "    \n",
    "    # Reconstruction Visualization\n",
    "    print(f\"\\n=== Reconstruction Comparison for {n_checkpoints} checkpoints ===\")\n",
    "    \n",
    "    # Function to normalize images for display\n",
    "    def normalize_for_display(img_tensor):\n",
    "        img = img_tensor.clone()\n",
    "        img_min, img_max = img.min(), img.max()\n",
    "        if img_max > img_min:\n",
    "            img = (img - img_min) / (img_max - img_min)\n",
    "        return img\n",
    "    \n",
    "    # Create reconstruction comparison plot\n",
    "    fig_recon, axes_recon = plt.subplots(2, n_checkpoints * 3, figsize=(4*n_checkpoints, 8))\n",
    "    if n_checkpoints == 1:\n",
    "        axes_recon = axes_recon.reshape(2, 3)\n",
    "    \n",
    "    for checkpoint_idx, (originals, reconstructions, name) in enumerate(zip(all_original_samples, all_reconstructions, checkpoint_names)):\n",
    "        for sample_idx in range(min(3, len(originals))):\n",
    "            col_idx = checkpoint_idx * 3 + sample_idx\n",
    "            \n",
    "            # Original image\n",
    "            orig_img = originals[sample_idx]\n",
    "            if orig_img.shape[0] == 1:  # Grayscale\n",
    "                axes_recon[0, col_idx].imshow(orig_img.squeeze(), cmap='gray')\n",
    "            else:  # RGB\n",
    "                axes_recon[0, col_idx].imshow(orig_img.permute(1, 2, 0))\n",
    "            \n",
    "            if sample_idx == 1:  # Middle sample gets the checkpoint name\n",
    "                axes_recon[0, col_idx].set_title(f'{name}\\nOriginal', fontsize=10)\n",
    "            else:\n",
    "                axes_recon[0, col_idx].set_title('Original', fontsize=10)\n",
    "            axes_recon[0, col_idx].axis('off')\n",
    "            \n",
    "            # Reconstructed image\n",
    "            recon_img = reconstructions[sample_idx]\n",
    "            if recon_img.shape[0] == 1:  # Grayscale\n",
    "                axes_recon[1, col_idx].imshow(recon_img.squeeze(), cmap='gray')\n",
    "            else:  # RGB\n",
    "                axes_recon[1, col_idx].imshow(recon_img.permute(1, 2, 0))\n",
    "            \n",
    "            if sample_idx == 1:  # Middle sample gets the checkpoint name\n",
    "                axes_recon[1, col_idx].set_title(f'{name}\\nReconstructed', fontsize=10)\n",
    "            else:\n",
    "                axes_recon[1, col_idx].set_title('Reconstructed', fontsize=10)\n",
    "            axes_recon[1, col_idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{comparison_name} - Reconstruction Comparison (3 samples per checkpoint)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # PCA Analysis\n",
    "    print(f\"\\n=== PCA Analysis for {n_checkpoints} checkpoints ===\")\n",
    "    \n",
    "    fig_pca, axes_pca = plt.subplots(2, n_checkpoints, figsize=(6*n_checkpoints, 12))\n",
    "    if n_checkpoints == 1:\n",
    "        axes_pca = axes_pca.reshape(2, 1)\n",
    "    \n",
    "    for i, (embeddings, labels, attrs, digits, name) in enumerate(zip(all_embeddings, all_labels, all_attrs, all_digits, checkpoint_names)):\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=3)\n",
    "        embeddings_pca = pca.fit_transform(embeddings)\n",
    "        embeddings_2d = embeddings_pca[:, [0, 1]]  # Use PC1 and PC2\n",
    "        # Plot 1: Colored by attributes\n",
    "        unique_attrs = np.unique(attrs)\n",
    "        colors_attrs = plt.cm.Set1(np.linspace(0, 1, len(unique_attrs)))\n",
    "        \n",
    "        for j, attr in enumerate(unique_attrs):\n",
    "            mask = attrs == attr\n",
    "            axes_pca[0, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                 c=[colors_attrs[j]], label=f'Attr {int(attr)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_pca[0, i].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "        axes_pca[0, i].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "        axes_pca[0, i].set_title(f'{name}\\nPCA - Colored by Attribute')\n",
    "        axes_pca[0, i].legend(fontsize=8)\n",
    "        axes_pca[0, i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Colored by digits\n",
    "        unique_digits = np.unique(digits)\n",
    "        colors_digits = plt.cm.tab10(np.linspace(0, 1, len(unique_digits)))\n",
    "        \n",
    "        for j, digit in enumerate(unique_digits):\n",
    "            mask = digits == digit\n",
    "            axes_pca[1, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                 c=[colors_digits[j]], label=f'Digit {int(digit)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_pca[1, i].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "        axes_pca[1, i].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "        axes_pca[1, i].set_title(f'{name}\\nPCA - Colored by Digit')\n",
    "        axes_pca[1, i].legend(fontsize=8)\n",
    "        axes_pca[1, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'{comparison_name} - PCA Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # UMAP Analysis\n",
    "    print(f\"\\n=== UMAP Analysis for {n_checkpoints} checkpoints ===\")\n",
    "    \n",
    "    fig_umap, axes_umap = plt.subplots(2, n_checkpoints, figsize=(6*n_checkpoints, 12))\n",
    "    if n_checkpoints == 1:\n",
    "        axes_umap = axes_umap.reshape(2, 1)\n",
    "    \n",
    "    for i, (embeddings, labels, attrs, digits, name) in enumerate(zip(all_embeddings, all_labels, all_attrs, all_digits, checkpoint_names)):\n",
    "        # Subsample for UMAP if needed\n",
    "        max_samples = 3000\n",
    "        if len(embeddings) > max_samples:\n",
    "            indices = np.random.choice(len(embeddings), max_samples, replace=False)\n",
    "            embeddings_subset = embeddings[indices]\n",
    "            attrs_subset = attrs[indices]\n",
    "            digits_subset = digits[indices]\n",
    "        else:\n",
    "            embeddings_subset = embeddings\n",
    "            attrs_subset = attrs\n",
    "            digits_subset = digits\n",
    "        \n",
    "        # Apply UMAP\n",
    "        # Use appropriate parameters for UMAP\n",
    "        n_neighbors = min(15, max(2, len(embeddings_subset)//10))\n",
    "        umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=n_neighbors, min_dist=0.1, verbose=False, n_jobs=1)\n",
    "        embeddings_2d = umap_reducer.fit_transform(embeddings_subset)\n",
    "        \n",
    "        # Plot 1: Colored by attributes\n",
    "        unique_attrs = np.unique(attrs_subset)\n",
    "        colors_attrs = plt.cm.Set1(np.linspace(0, 1, len(unique_attrs)))\n",
    "        \n",
    "        for j, attr in enumerate(unique_attrs):\n",
    "            mask = attrs_subset == attr\n",
    "            axes_umap[0, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                  c=[colors_attrs[j]], label=f'Attr {int(attr)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_umap[0, i].set_xlabel('UMAP Dimension 1')\n",
    "        axes_umap[0, i].set_ylabel('UMAP Dimension 2')\n",
    "        axes_umap[0, i].set_title(f'{name}\\nUMAP - Colored by Attribute')\n",
    "        axes_umap[0, i].legend(fontsize=8)\n",
    "        axes_umap[0, i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Colored by digits\n",
    "        unique_digits = np.unique(digits_subset)\n",
    "        colors_digits = plt.cm.tab10(np.linspace(0, 1, len(unique_digits)))\n",
    "        \n",
    "        for j, digit in enumerate(unique_digits):\n",
    "            mask = digits_subset == digit\n",
    "            axes_umap[1, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                  c=[colors_digits[j]], label=f'Digit {int(digit)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_umap[1, i].set_xlabel('UMAP Dimension 1')\n",
    "        axes_umap[1, i].set_ylabel('UMAP Dimension 2')\n",
    "        axes_umap[1, i].set_title(f'{name}\\nUMAP - Colored by Digit')\n",
    "        axes_umap[1, i].legend(fontsize=8)\n",
    "        axes_umap[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'{comparison_name} - UMAP Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAnalysis complete for {n_checkpoints} checkpoints!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eccc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 checkpoint files (sorted by training size):\n",
      "  1: featurizer_size10_spur0p05.pt (size: 10)\n",
      "  2: featurizer_size10_spur0p1.pt (size: 10)\n",
      "  3: featurizer_size10_spur0p5.pt (size: 10)\n",
      "  4: featurizer_size10_spur0p2.pt (size: 10)\n",
      "  5: featurizer_size10_spur0p01.pt (size: 10)\n",
      "  6: featurizer_size37_spur0p2.pt (size: 37)\n",
      "  7: featurizer_size37_spur0p01.pt (size: 37)\n",
      "  8: featurizer_size37_spur0p05.pt (size: 37)\n",
      "  9: featurizer_size37_spur0p5.pt (size: 37)\n",
      "  10: featurizer_size37_spur0p1.pt (size: 37)\n",
      "  11: featurizer_size144_spur0p5.pt (size: 144)\n",
      "  12: featurizer_size144_spur0p05.pt (size: 144)\n",
      "  13: featurizer_size144_spur0p2.pt (size: 144)\n",
      "  14: featurizer_size144_spur0p1.pt (size: 144)\n",
      "  15: featurizer_size144_spur0p01.pt (size: 144)\n",
      "  16: featurizer_size547_spur0p01.pt (size: 547)\n",
      "  17: featurizer_size547_spur0p2.pt (size: 547)\n",
      "  18: featurizer_size547_spur0p05.pt (size: 547)\n",
      "  19: featurizer_size547_spur0p5.pt (size: 547)\n",
      "  20: featurizer_size547_spur0p1.pt (size: 547)\n",
      "  21: featurizer_size2080_spur0p1.pt (size: 2080)\n",
      "  22: featurizer_size2080_spur0p5.pt (size: 2080)\n",
      "  23: featurizer_size2080_spur0p01.pt (size: 2080)\n",
      "  24: featurizer_size2080_spur0p05.pt (size: 2080)\n",
      "  25: featurizer_size2080_spur0p2.pt (size: 2080)\n",
      "  26: featurizer_size7899_spur0p2.pt (size: 7899)\n",
      "  27: featurizer_size7899_spur0p1.pt (size: 7899)\n",
      "  28: featurizer_size7899_spur0p01.pt (size: 7899)\n",
      "  29: featurizer_size7899_spur0p5.pt (size: 7899)\n",
      "  30: featurizer_size7899_spur0p05.pt (size: 7899)\n",
      "  31: featurizer_size30000_spur0p5.pt (size: 30000)\n",
      "  32: featurizer_size30000_spur0p01.pt (size: 30000)\n",
      "  33: featurizer_size30000_spur0p2.pt (size: 30000)\n",
      "  34: featurizer_size30000_spur0p05.pt (size: 30000)\n",
      "  35: featurizer_size30000_spur0p1.pt (size: 30000)\n",
      "  Error processing featurizer_size10_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size10_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size10_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size10_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size10_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size37_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size37_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size37_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size37_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size37_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size144_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size144_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size144_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size144_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size144_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size547_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size2080_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size7899_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "No checkpoints were successfully processed.\n",
      "  Error processing featurizer_size30000_spur0p5: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p01: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p2: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p05: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "  Error processing featurizer_size30000_spur0p1: Error(s) in loading state_dict for VAE:\n",
      "\tMissing key(s) in state_dict: \"featurizer.conv1.weight\", \"featurizer.conv1.bias\", \"featurizer.conv2.weight\", \"featurizer.conv2.bias\", \"featurizer.conv3.weight\", \"featurizer.conv3.bias\", \"featurizer.conv4.weight\", \"featurizer.conv4.bias\", \"featurizer.bn0.weight\", \"featurizer.bn0.bias\", \"featurizer.bn1.weight\", \"featurizer.bn1.bias\", \"featurizer.bn2.weight\", \"featurizer.bn2.bias\", \"featurizer.bn3.weight\", \"featurizer.bn3.bias\", \"encoder_mu.weight\", \"encoder_mu.bias\", \"encoder_logvar.weight\", \"encoder_logvar.bias\", \"decoder.fc.weight\", \"decoder.fc.bias\", \"decoder.deconv.0.weight\", \"decoder.deconv.0.bias\", \"decoder.deconv.1.weight\", \"decoder.deconv.1.bias\", \"decoder.deconv.1.running_mean\", \"decoder.deconv.1.running_var\", \"decoder.deconv.3.weight\", \"decoder.deconv.3.bias\", \"decoder.deconv.4.weight\", \"decoder.deconv.4.bias\", \"decoder.deconv.4.running_mean\", \"decoder.deconv.4.running_var\", \"decoder.deconv.6.weight\", \"decoder.deconv.6.bias\". \n",
      "\tUnexpected key(s) in state_dict: \"conv1.weight\", \"conv1.bias\", \"conv2.weight\", \"conv2.bias\", \"conv3.weight\", \"conv3.bias\", \"conv4.weight\", \"conv4.bias\", \"bn0.weight\", \"bn0.bias\", \"bn1.weight\", \"bn1.bias\", \"bn2.weight\", \"bn2.bias\", \"bn3.weight\", \"bn3.bias\". \n",
      "No checkpoints were successfully processed.\n"
     ]
    }
   ],
   "source": [
    "# Call the analysis function to visualize checkpoint performance\n",
    "# Ensure the `timestamp_root` variable is set from the training cell above.\n",
    "# This path should point to the folder where your VAE checkpoints are saved.\n",
    "\n",
    "\n",
    "checkpoint_folder_path = os.path.join(timestamp_root, 'checkpoints', 'VAE')\n",
    "#or modify to your own local folder\n",
    "\n",
    "\n",
    "if os.path.exists(checkpoint_folder_path):\n",
    "    analyze_checkpoints_folder(\n",
    "        checkpoint_folder=checkpoint_folder_path, \n",
    "        eval_dataset=test_dataset, \n",
    "        comparison_name=f\"VAE Analysis (spur={cmnist_spur_prob})\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"Checkpoint folder not found, skipping analysis: {checkpoint_folder_path}\")\n",
    "    print(\"Please ensure that the training process has completed and generated checkpoints.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
