{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4cd1b81",
   "metadata": {},
   "source": [
    "# Contrastive Learning Experiment Notebook\n",
    "\n",
    "Train algorithms on increasing dataset sizes and plot risk/likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbf6cf4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Environment, imports, device selection, and reproducibility seeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b518c902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mila/t/tom.marty/invariant_bench/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using seed: 0\n"
     ]
    }
   ],
   "source": [
    "# Imports and path setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Add project root to path if needed (before importing project modules)\n",
    "sys.path.append(str(Path('..').resolve()))\n",
    "\n",
    "from source.dataset import datasets\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from tqdm.auto import tqdm\n",
    "from source.utils import hparams_registry\n",
    "\n",
    "# Select device: use GPU if available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "# Reproducibility\n",
    "seed = int(os.environ.get('SEED', 0))\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "print(f'Using seed: {seed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d669f4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions for robust error handling loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from source.utils.misc import group_counts, build_group_index, w, safe_mean, InfiniteDataLoader, find_timestamp_root\n",
    "print(\"Utility functions for robust error handling loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad476be2",
   "metadata": {},
   "source": [
    "## Experiment configuration\n",
    "\n",
    "Dataset choice, learners, and result containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195cc4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "  Dataset: CMNIST\n",
      "  Data path: /home/mila/t/tom.marty/scratch/invariant_bench/data/benchmark\n",
      "  Stratified sampling: True\n",
      "  Debug mode: True\n"
     ]
    }
   ],
   "source": [
    "DEBUG = True\n",
    "\n",
    "# Experiment config\n",
    "DATA_PATH = os.path.expanduser('~/scratch/invariant_bench/data/benchmark')\n",
    "\n",
    "DATASET_NAME = 'CMNIST'\n",
    "NETWORK_NAME = 'mnist_cnn'  # 'resnet', 'simple_mlp', or 'mnist_cnn'\n",
    "BATCH_SIZE = 128\n",
    "NUM_FIT = 7 # number of points in the PCL curve\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "USE_STRATIFIED = True # Toggle: use stratified (label, attr) sampling such that the class ratio is preserved\n",
    "ROBUST_TRAINING = True  # Enable     robust error handling\n",
    "MAX_RETRIES = 3  # Maximum number of retries for failed operations\n",
    "CONTINUE_ON_ERROR = True  # Continue with next algorithm/size if current fails\n",
    "SAVE_PARTIAL_RESULTS = True  # Save results even if some experiments fail\n",
    "\n",
    "# Early stopping configuration\n",
    "ES_MIN_DELTA = 0\n",
    "ES_PATIENCE = 3         # checkpoints without improvement before stopping\n",
    "\n",
    "\n",
    "print('Config:')\n",
    "print(f'  Dataset: {DATASET_NAME}')\n",
    "print(f'  Data path: {DATA_PATH}')\n",
    "print(f'  Stratified sampling: {USE_STRATIFIED}')\n",
    "print(f'  Debug mode: {DEBUG}')\n",
    "\n",
    "# Prepare per-learner results storage\n",
    "val_loss_map = []           # validation loss means (best)\n",
    "train_loss_map = []         # training loss mean (per size)\n",
    "test_loss_map  = []         # test loss means (final model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d32c5c",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Defaults and dataset-specific overrides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ebcc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters template\n",
    "import os\n",
    "from source.utils.misc import safe_float_env\n",
    "\n",
    "# We'll derive specific hparams per learner in the training loop\n",
    "base_hparams = hparams_registry.default_hparams('ERM', DATASET_NAME)\n",
    "base_hparams['image_arch'] = NETWORK_NAME\n",
    "\n",
    "if NETWORK_NAME == 'resnet':\n",
    "    base_hparams.update({\n",
    "        'pretrained': False,\n",
    "        'input_size': 224\n",
    "    })\n",
    "elif NETWORK_NAME == 'simple_mlp' or NETWORK_NAME == 'mnist_cnn':\n",
    "    base_hparams.update({\n",
    "        'input_size': 28, \n",
    "        'lr': 1e-3,\n",
    "    })\n",
    "\n",
    "\n",
    "#TODO check that pretrained=FALSE for ResNet works\n",
    "\"\"\"\n",
    "Colored MNIST specific hyperparameters:\n",
    "- cmnist_label_prob: Probability of label imbalance (default 0.5)\n",
    "- cmnist_attr_prob: Probability of attribute imbalance (default 0.5)\n",
    "- cmnist_spur_prob: Controls the summed diagonal proportion (0,1). The more this is towards 0, the more the color is spuriously correlated with the label. \n",
    "\"\"\"\n",
    "\n",
    "cmnist_label_prob = safe_float_env(\"CMNIST_LABEL_PROB\", 0.5)\n",
    "cmnist_attr_prob = safe_float_env(\"CMNIST_ATTR_PROB\", 0.5)\n",
    "cmnist_spur_prob = safe_float_env(\"CMNIST_SPUR_PROB\", 0.1)\n",
    "\n",
    "if DATASET_NAME == 'CMNIST':\n",
    "    base_hparams.update({\n",
    "        'cmnist_label_prob': cmnist_label_prob,\n",
    "        'cmnist_attr_prob': cmnist_attr_prob, \n",
    "        'cmnist_spur_prob': cmnist_spur_prob,\n",
    "        'cmnist_flip_prob': 0.0,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85799a7a",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Load train/val/test splits and preview samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa12b7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets:\n",
      "  Train size: 100 | Val size: 100 | Test size: 100 (restricted)\n",
      "  Input shape: (3, 28, 28) | data_type: images\n",
      "  num_labels: 2 | num_attributes: 2\n",
      "Stratified groups (counts): {(0, 0): 44, (0, 1): 4, (1, 0): 6, (1, 1): 46}\n",
      "\n",
      "Class distribution:\n",
      "       count  percentage\n",
      "class                   \n",
      "0         48        48.0\n",
      "1         52        52.0\n",
      "\n",
      "Attribute distribution:\n",
      "           count  percentage\n",
      "attribute                   \n",
      "0             50        50.0\n",
      "1             50        50.0\n",
      "\n",
      "Group (class, attribute) distribution:\n",
      "                 count  percentage\n",
      "class attribute                   \n",
      "0     0             44        44.0\n",
      "      1              4         4.0\n",
      "1     0              6         6.0\n",
      "      1             46        46.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attach key attributes to Subset objects for easier access\n",
    "def attach_dataset_attributes(subset):\n",
    "    \"\"\" Attach key attributes from the underlying dataset to a Subset object.\"\"\"\n",
    "    if hasattr(subset, 'dataset'):\n",
    "        for attr in ['INPUT_SHAPE', 'num_labels', 'num_attributes', 'data_type']:\n",
    "            if hasattr(subset.dataset, attr):\n",
    "                setattr(subset, attr, getattr(subset.dataset, attr))\n",
    "\n",
    "\n",
    "# Create a perfectly balanced test dataset (all probabilities set to 0.5)\n",
    "balanced_test_hparams = base_hparams.copy()\n",
    "balanced_test_hparams.update({\n",
    "    'cmnist_label_prob': 0.5,\n",
    "    'cmnist_attr_prob': 0.5,\n",
    "    'cmnist_spur_prob': 0.5,\n",
    "    'cmnist_flip_prob': 0.0\n",
    "})\n",
    "\n",
    "DatasetClass = getattr(datasets, DATASET_NAME)\n",
    "train_dataset = DatasetClass(DATA_PATH, 'tr', base_hparams)\n",
    "val_dataset = DatasetClass(DATA_PATH, 'va', base_hparams)\n",
    "test_dataset = DatasetClass(DATA_PATH, 'te', balanced_test_hparams)\n",
    "\n",
    "# If debug, reduce all datasets to size 100\n",
    "if DEBUG:\n",
    "    train_indices = random.sample(range(len(train_dataset)), min(100, len(train_dataset)))\n",
    "    val_indices = random.sample(range(len(val_dataset)), min(100, len(val_dataset)))\n",
    "    test_indices = random.sample(range(len(test_dataset)), min(100, len(test_dataset)))\n",
    "    train_dataset = Subset(train_dataset, train_indices)\n",
    "    val_dataset = Subset(val_dataset, val_indices)\n",
    "    test_dataset = Subset(test_dataset, test_indices)\n",
    "    dataset_sizes = [10, 100]\n",
    "else:\n",
    "    max_train_size = len(train_dataset)\n",
    "    dataset_sizes = np.logspace(1, np.log10(max_train_size), num=NUM_FIT, dtype=int).tolist()\n",
    "\n",
    "    \n",
    "attach_dataset_attributes(train_dataset)\n",
    "attach_dataset_attributes(val_dataset)\n",
    "attach_dataset_attributes(test_dataset)\n",
    "\n",
    "indices = list(range(len(train_dataset)))\n",
    "random.shuffle(indices)\n",
    "\n",
    "input_shape = train_dataset.INPUT_SHAPE\n",
    "num_labels = train_dataset.num_labels\n",
    "num_attributes = train_dataset.num_attributes\n",
    "data_type = getattr(train_dataset, 'data_type', 'images')\n",
    "\n",
    "print('Datasets:')\n",
    "print(f'  Train size: {len(train_dataset)} | Val size: {len(val_dataset)} | Test size: {len(test_dataset)} (restricted)')\n",
    "print(f'  Input shape: {input_shape} | data_type: {data_type}')\n",
    "print(f'  num_labels: {num_labels} | num_attributes: {num_attributes}')\n",
    "\n",
    "    \n",
    "if USE_STRATIFIED:\n",
    "    group_to_indices = build_group_index(train_dataset)\n",
    "    group_counts_dict = {k: len(v) for k, v in sorted(group_to_indices.items())}\n",
    "    print('Stratified groups (counts):', group_counts_dict)\n",
    "\n",
    "    # Aggregate counts for each class and attribute\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    df = pd.DataFrame([{'class': k[0], 'attribute': k[1], 'count': v} for k, v in group_counts_dict.items()])\n",
    "    class_counts = df.groupby('class')['count'].sum()\n",
    "    attr_counts = df.groupby('attribute')['count'].sum()\n",
    "    total = df['count'].sum()\n",
    "\n",
    "    print('\\nClass distribution:')\n",
    "    class_dist = df.groupby('class')['count'].sum().to_frame()\n",
    "    class_dist['percentage'] = (class_dist['count'] / total * 100).round(2)\n",
    "    print(class_dist.to_string())\n",
    "\n",
    "    print('\\nAttribute distribution:')\n",
    "    attr_dist = df.groupby('attribute')['count'].sum().to_frame()\n",
    "    attr_dist['percentage'] = (attr_dist['count'] / total * 100).round(2)\n",
    "    print(attr_dist.to_string())\n",
    "\n",
    "    print('\\nGroup (class, attribute) distribution:')\n",
    "    group_dist = df.set_index(['class','attribute'])\n",
    "    group_dist['percentage'] = (group_dist['count'] / total * 100).round(2)\n",
    "    print(group_dist.to_string())\n",
    "    \n",
    "# Preview a few samples (images only)\n",
    "if data_type == 'images':\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(8, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for k, ax in enumerate(axes):\n",
    "        idx, x, y, a, _ = train_dataset[k]\n",
    "        # Scale per-image to [0,1] for visualization\n",
    "        x_vis = x.detach().cpu()\n",
    "        x_min, x_max = x_vis.min(), x_vis.max()\n",
    "        x_vis = (x_vis - x_min) / (x_max - x_min + 1e-6)\n",
    "        ax.imshow(x_vis.permute(1, 2, 0))\n",
    "        ax.set_title(f'Label: {int(y)}, Attr: {int(a)}')\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Non-image dataset preview omitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1be384",
   "metadata": {},
   "source": [
    "## Training and evaluation\n",
    "\n",
    "Main training loop over dataset sizes and algorithms with robust error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad6a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on dataset sizes: [10, 100]\n",
      "\n",
      "--- Training with size=10 ---\n",
      "[Init] size=10 | data_type=images | input_shape=(3, 28, 28) | labels=2 | attrs=2 | stratified=True\n",
      "GPU memory after model creation: 0.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 160\n",
      "[Final] size=10 | train_loss=4778.9805 | val_loss=57329.4141 | test_loss=62516.3008\n",
      "\n",
      "--- Training with size=100 ---\n",
      "[Init] size=100 | data_type=images | input_shape=(3, 28, 28) | labels=2 | attrs=2 | stratified=True\n",
      "GPU memory after model creation: 0.02 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at step 160\n",
      "[Final] size=100 | train_loss=48299.7898 | val_loss=49139.7383 | test_loss=54007.5820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "import gc\n",
    "import torch\n",
    "from source.learning.algorithms import VAE\n",
    "\n",
    "# Use environment variable for timestamp if set, else fallback to current time\n",
    "base_timestamp = os.environ.get('RESULT_FOLDER', time.strftime('%Y%m%d-%H%M%S'))\n",
    "\n",
    "result_dir = os.path.join(\"../results\", base_timestamp)\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "log_file = os.path.join(result_dir, 'training.log')\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Enhanced error tracking\n",
    "ERROR_LOG = {\n",
    "    'size_failures': {},\n",
    "    'step_failures': {},\n",
    "    'validation_failures': {},\n",
    "    'test_failures': {}\n",
    "}\n",
    "\n",
    "# Function to clear GPU memory\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory and run garbage collection\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Function to convert tensor to float (detach from GPU)\n",
    "def tensor_to_float(tensor_val):\n",
    "    \"\"\"Convert tensor to float, detaching from GPU memory\"\"\"\n",
    "    if isinstance(tensor_val, dict):\n",
    "        return {k: tensor_to_float(v) for k, v in tensor_val.items()}\n",
    "    elif hasattr(tensor_val, 'item'):\n",
    "        return tensor_val.detach().cpu().item()\n",
    "    elif hasattr(tensor_val, 'detach'):\n",
    "        return tensor_val.detach().cpu().numpy()\n",
    "    else:\n",
    "        return float(tensor_val)\n",
    "\n",
    "# Precompute subsets for each dataset size\n",
    "subset_indices_map = {}\n",
    "for size in dataset_sizes:\n",
    "    if USE_STRATIFIED:\n",
    "        subset_indices = w(group_to_indices, size, rng=np.random.RandomState(0 + size))\n",
    "        subset_indices_map[size] = subset_indices\n",
    "    else:\n",
    "        subset_indices = random.sample(indices, min(size, len(indices)))\n",
    "        subset_indices_map[size] = subset_indices\n",
    "\n",
    "# Initialize tracking\n",
    "hparams = base_hparams.copy()\n",
    "\n",
    "val_loss_map = [float('nan')] * len(dataset_sizes)\n",
    "train_loss_map = [float('nan')] * len(dataset_sizes)\n",
    "test_loss_map = [float('nan')] * len(dataset_sizes)\n",
    "\n",
    "print(f\"Training on dataset sizes: {dataset_sizes}\")\n",
    "\n",
    "for idx, size in enumerate(dataset_sizes):\n",
    "    print(f\"\\n--- Training with size={size} ---\")\n",
    "    \n",
    "\n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    subset_indices = subset_indices_map[size]\n",
    "    train_subset = Subset(train_dataset, subset_indices)\n",
    "    attach_dataset_attributes(train_subset)\n",
    "\n",
    "    input_shape = train_subset.INPUT_SHAPE\n",
    "    num_labels = train_subset.num_labels\n",
    "    num_attributes = train_subset.num_attributes\n",
    "    data_type = getattr(train_subset, 'data_type', 'images')\n",
    "    hparams = hparams_registry.default_hparams(\"VAE\", DATASET_NAME)\n",
    "    hparams.update(base_hparams)\n",
    "    \n",
    "    learner = VAE(data_type, input_shape, num_labels, num_attributes, len(train_subset), hparams)\n",
    "    if hasattr(learner, 'to'):\n",
    "        learner = learner.to(DEVICE)\n",
    "\n",
    "    print(f\"[Init] size={size} | data_type={data_type} | input_shape={input_shape} | labels={num_labels} | attrs={num_attributes} | stratified={USE_STRATIFIED}\")\n",
    "    print(f\"GPU memory after model creation: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "\n",
    "    checkpoint_freq = max(20, math.ceil(len(train_subset) / BATCH_SIZE))\n",
    "    best_val = float('inf')\n",
    "    bad_checks = 0\n",
    "\n",
    "    # Include spur_prob in checkpoint names\n",
    "    spur_prob_str = str(cmnist_spur_prob).replace('.', 'p')\n",
    "    \n",
    "    # Get the root timestamp directory for saving checkpoints\n",
    "    timestamp_root = find_timestamp_root(result_dir)\n",
    "    vae_path = os.path.join(timestamp_root, 'checkpoints', 'VAE', f'vae_size{size}_spur{spur_prob_str}.pt')\n",
    "    featurizer_path = os.path.join(timestamp_root, 'checkpoints', f'featurizer_size{size}_spur{spur_prob_str}.pt')\n",
    "    os.makedirs(os.path.dirname(vae_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(featurizer_path), exist_ok=True)\n",
    "\n",
    "    train_losses_epoch = []\n",
    "    learner.train()\n",
    "\n",
    "    train_minibatches_iterator = iter(InfiniteDataLoader(\n",
    "        train_subset, None, BATCH_SIZE, NUM_WORKERS\n",
    "    ))\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    pbar = tqdm(itertools.count(), desc=f\"Train size={size}\", leave=False)\n",
    "    for step in pbar:\n",
    "        try:\n",
    "            # Get next training batch - now includes digit value\n",
    "            i, x, y, a, digit = next(train_minibatches_iterator)\n",
    "            x, y, a = x.to(DEVICE), y.to(DEVICE), a.to(DEVICE)\n",
    "\n",
    "            cur_loss = learner.update((i, x, y, a), step)\n",
    "            \n",
    "            # Convert loss to float immediately to free GPU memory\n",
    "            cur_loss_float = tensor_to_float(cur_loss)\n",
    "            train_losses_epoch.append(cur_loss_float)\n",
    "            \n",
    "            do_check = (\n",
    "                step > 0 and\n",
    "                (step % checkpoint_freq == 0 or step == 1000)  # Check at regular intervals\n",
    "            )\n",
    "            \n",
    "            if do_check:\n",
    "                # Compute validation loss - now handles digit value\n",
    "                learner.eval()\n",
    "                val_losses_step = []\n",
    "                \n",
    "                with torch.no_grad():  # Important: disable gradients during validation\n",
    "                    for i_val, x_val, y_val, a_val, digit_val in val_loader:\n",
    "                        x_val, y_val = x_val.to(DEVICE), y_val.to(DEVICE)\n",
    "                        _, loss = learner.predict(x_val, y_val, return_loss=True)\n",
    "                        # Convert to float immediately and move to CPU\n",
    "                        val_losses_step.append(tensor_to_float(loss))\n",
    "                        \n",
    "                learner.train()\n",
    "                \n",
    "                mean_val_loss = sum(val_losses_step) / len(val_losses_step)\n",
    "                \n",
    "                improved = mean_val_loss < (best_val - ES_MIN_DELTA)\n",
    "                if improved:\n",
    "                    best_val = mean_val_loss\n",
    "                    bad_checks = 0\n",
    "                    torch.save(learner.state_dict(), vae_path)\n",
    "                    torch.save(learner.featurizer.state_dict(), featurizer_path)\n",
    "                else:\n",
    "                    bad_checks += 1\n",
    "\n",
    "                # Extract loss value from dictionary for display\n",
    "                cur_loss_val = cur_loss_float.get(\"loss\", 0.0) if isinstance(cur_loss_float, dict) else cur_loss_float\n",
    "                pbar.set_description(f\"Train size={size} | step={step} | train_loss={cur_loss_val:.3f} | val_loss={mean_val_loss:.3f} | bad_checks={bad_checks}/{ES_PATIENCE}\")\n",
    "                \n",
    "                # Clear validation losses from memory\n",
    "                del val_losses_step\n",
    "                \n",
    "                if bad_checks >= ES_PATIENCE:\n",
    "                    print(f\"Early stopping at step {step}\")\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            if ROBUST_TRAINING:\n",
    "                print(f\"Error at step {step}: {e}\")\n",
    "                ERROR_LOG['step_failures'][f'size_{size}_step_{step}'] = str(e)\n",
    "                if CONTINUE_ON_ERROR:\n",
    "                    continue\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    # Load best model and compute final metrics\n",
    "    try:\n",
    "        learner.load_state_dict(torch.load(vae_path))\n",
    "        learner.eval()\n",
    "        \n",
    "        # Validation loss\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i_val, x_val, y_val, a_val, digit_val in val_loader:\n",
    "                x_val, y_val, a_val = x_val.to(DEVICE), y_val.to(DEVICE), a_val.to(DEVICE)\n",
    "                _, loss = learner.predict(x_val, y_val, return_loss=True)\n",
    "                val_losses.append(tensor_to_float(loss))\n",
    "        val_loss = sum(val_losses) / len(val_losses)\n",
    "        val_loss_map[idx] = val_loss\n",
    "        del val_losses  # Clear from memory\n",
    "        \n",
    "        # Test loss  \n",
    "        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "        test_losses = []\n",
    "        with torch.no_grad():\n",
    "            for i_test, x_test, y_test, a_test, digit_test in test_loader:\n",
    "                x_test, y_test, a_test = x_test.to(DEVICE), y_test.to(DEVICE), a_test.to(DEVICE)\n",
    "                _, loss = learner.predict(x_test, y_test, return_loss=True)\n",
    "                test_losses.append(tensor_to_float(loss))\n",
    "        test_loss = sum(test_losses) / len(test_losses)\n",
    "        test_loss_map[idx] = test_loss\n",
    "        del test_losses  # Clear from memory\n",
    "        \n",
    "        # Training loss (from last epoch) - now working with floats\n",
    "        recent_losses = train_losses_epoch[-min(len(train_losses_epoch), 10):]\n",
    "        if isinstance(recent_losses[0], dict):\n",
    "            train_loss_map[idx] = sum([loss.get(\"loss\", 0.0) for loss in recent_losses]) / len(recent_losses)\n",
    "        else:\n",
    "            train_loss_map[idx] = sum(recent_losses) / len(recent_losses)\n",
    "        \n",
    "        print(f\"[Final] size={size} | train_loss={train_loss_map[idx]:.4f} | val_loss={val_loss:.4f} | test_loss={test_loss:.4f}\")\n",
    "        logger.info(f\"Completed size={size} | train_loss={train_loss_map[idx]:.4f} | val_loss={val_loss:.4f} | test_loss={test_loss:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        if ROBUST_TRAINING:\n",
    "            print(f\"Error in evaluation for size {size}: {e}\")\n",
    "            ERROR_LOG['validation_failures'][f'size_{size}'] = str(e)\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7497ff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Checkpoint Analysis: PCA and UMAP Visualization Function\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from source.learning.algorithms import VAE\n",
    "\n",
    "def analyze_checkpoints_folder(checkpoint_folder, eval_dataset, comparison_name=\"Checkpoint Comparison\"):\n",
    "    \"\"\"\n",
    "    Load multiple VAE checkpoints and generate PCA and UMAP visualizations for each.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_folder (str): Path to folder containing .pt checkpoint files\n",
    "        eval_dataset: Dataset to extract embeddings from\n",
    "        comparison_name (str): Name for the comparison plots\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all .pt files in the folder\n",
    "    checkpoint_files = glob.glob(os.path.join(checkpoint_folder, \"*.pt\"))\n",
    "    \n",
    "    if not checkpoint_files:\n",
    "        print(f\"No .pt checkpoint files found in {checkpoint_folder}\")\n",
    "        return\n",
    "    \n",
    "    # Sort checkpoints by training size (extract number from filename like vae_size547.pt)\n",
    "    def extract_size_from_filename(filepath):\n",
    "        filename = os.path.basename(filepath)\n",
    "        # Look for pattern like \"size123\" in filename\n",
    "        import re\n",
    "        match = re.search(r'size(\\d+)', filename)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "        else:\n",
    "            # Fallback to alphabetical sorting if no size found\n",
    "            return 0\n",
    "    \n",
    "    checkpoint_files.sort(key=extract_size_from_filename)\n",
    "    print(f\"Found {len(checkpoint_files)} checkpoint files (sorted by training size):\")\n",
    "    for i, file in enumerate(checkpoint_files):\n",
    "        size = extract_size_from_filename(file)\n",
    "        print(f\"  {i+1}: {os.path.basename(file)} (size: {size})\")\n",
    "    \n",
    "    # Prepare evaluation dataset\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "    \n",
    "    # Store results for all checkpoints\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "    all_attrs = []\n",
    "    all_digits = []\n",
    "    all_reconstructions = []  # Store reconstructions for visualization\n",
    "    all_original_samples = []  # Store original samples for reconstruction comparison\n",
    "    checkpoint_names = []\n",
    "    \n",
    "    for checkpoint_path in checkpoint_files:\n",
    "        checkpoint_name = os.path.basename(checkpoint_path).replace('.pt', '')\n",
    "        training_size = extract_size_from_filename(checkpoint_path)\n",
    "        display_name = f\"Size {training_size}\" if training_size > 0 else checkpoint_name\n",
    "        checkpoint_names.append(display_name)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Create a new learner instance (using correct parameter names)\n",
    "            # Get the current hyperparameters to use\n",
    "            current_hparams = hparams if 'hparams' in globals() else base_hparams\n",
    "            \n",
    "            temp_learner = VAE(\n",
    "                data_type=getattr(eval_dataset, 'data_type', 'images'),\n",
    "                input_shape=eval_dataset.INPUT_SHAPE,\n",
    "                num_classes=eval_dataset.num_labels,  # VAE expects num_classes, not num_labels\n",
    "                num_attributes=eval_dataset.num_attributes,\n",
    "                num_examples=len(eval_dataset),\n",
    "                hparams=current_hparams\n",
    "            )\n",
    "            \n",
    "            # Load checkpoint\n",
    "            temp_learner.load_state_dict(torch.load(checkpoint_path, map_location=DEVICE))\n",
    "            temp_learner = temp_learner.to(DEVICE)\n",
    "            temp_learner.eval()\n",
    "            \n",
    "            # Extract embeddings\n",
    "            embeddings_list = []\n",
    "            labels_list = []\n",
    "            attrs_list = []\n",
    "            digits_list = []\n",
    "            \n",
    "            # Get 3 samples for reconstruction visualization\n",
    "            sample_originals = []\n",
    "            sample_reconstructions = []\n",
    "            sample_labels = []\n",
    "            sample_attrs = []\n",
    "            sample_digits = []\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, (i_batch, x_batch, y_batch, a_batch, digit_batch) in enumerate(eval_loader):\n",
    "                    x_batch = x_batch.to(DEVICE)\n",
    "                    \n",
    "                    # Get embeddings from the featurizer\n",
    "                    if hasattr(temp_learner, 'featurizer'):\n",
    "                        features = temp_learner.featurizer(x_batch)\n",
    "                    else:\n",
    "                        # Fallback: use encoder mean\n",
    "                        features = temp_learner.encode(x_batch)[0]\n",
    "                    \n",
    "                    # Move to CPU and convert to numpy\n",
    "                    embeddings_list.append(features.cpu().numpy())\n",
    "                    labels_list.append(y_batch.numpy())\n",
    "                    attrs_list.append(a_batch.numpy())\n",
    "                    digits_list.append(digit_batch.numpy())\n",
    "                    \n",
    "                    # Collect first 3 samples for reconstruction visualization\n",
    "                    if batch_idx == 0 and len(sample_originals) < 3:\n",
    "                        # Get reconstructions for the first 3 samples\n",
    "                        n_samples_to_get = min(3, len(x_batch))\n",
    "                        x_samples = x_batch[:n_samples_to_get]\n",
    "                        \n",
    "                        # Encode and decode\n",
    "                        mu, logvar = temp_learner.encode(x_samples)\n",
    "                        reconstructed = temp_learner.decode(mu)  # Use mean reconstruction\n",
    "                        \n",
    "                        # Store samples\n",
    "                        sample_originals.extend([x_samples[i].cpu() for i in range(n_samples_to_get)])\n",
    "                        sample_reconstructions.extend([reconstructed[i].cpu() for i in range(n_samples_to_get)])\n",
    "                        sample_labels.extend([y_batch[i].item() for i in range(n_samples_to_get)])\n",
    "                        sample_attrs.extend([a_batch[i].item() for i in range(n_samples_to_get)])\n",
    "                        sample_digits.extend([digit_batch[i].item() for i in range(n_samples_to_get)])\n",
    "            \n",
    "            # Concatenate all batches\n",
    "            embeddings = np.concatenate(embeddings_list, axis=0)\n",
    "            labels = np.concatenate(labels_list, axis=0)\n",
    "            attrs = np.concatenate(attrs_list, axis=0)\n",
    "            digits = np.concatenate(digits_list, axis=0)\n",
    "            \n",
    "            all_embeddings.append(embeddings)\n",
    "            all_labels.append(labels)\n",
    "            all_attrs.append(attrs)\n",
    "            all_digits.append(digits)\n",
    "            all_reconstructions.append(sample_reconstructions)\n",
    "            all_original_samples.append(sample_originals)\n",
    "            \n",
    "\n",
    "            # Clean up\n",
    "            del temp_learner\n",
    "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {checkpoint_name}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not all_embeddings:\n",
    "        print(\"No checkpoints were successfully processed.\")\n",
    "        return\n",
    "    \n",
    "    # Create comparison plots\n",
    "    n_checkpoints = len(all_embeddings)\n",
    "    \n",
    "    # Reconstruction Visualization\n",
    "    print(f\"\\n=== Reconstruction Comparison for {n_checkpoints} checkpoints ===\")\n",
    "    \n",
    "    # Function to normalize images for display\n",
    "    def normalize_for_display(img_tensor):\n",
    "        img = img_tensor.clone()\n",
    "        img_min, img_max = img.min(), img.max()\n",
    "        if img_max > img_min:\n",
    "            img = (img - img_min) / (img_max - img_min)\n",
    "        return img\n",
    "    \n",
    "    # Create reconstruction comparison plot\n",
    "    fig_recon, axes_recon = plt.subplots(2, n_checkpoints * 3, figsize=(4*n_checkpoints, 8))\n",
    "    if n_checkpoints == 1:\n",
    "        axes_recon = axes_recon.reshape(2, 3)\n",
    "    \n",
    "    for checkpoint_idx, (originals, reconstructions, name) in enumerate(zip(all_original_samples, all_reconstructions, checkpoint_names)):\n",
    "        for sample_idx in range(min(3, len(originals))):\n",
    "            col_idx = checkpoint_idx * 3 + sample_idx\n",
    "            \n",
    "            # Original image\n",
    "            orig_img = originals[sample_idx]\n",
    "            if orig_img.shape[0] == 1:  # Grayscale\n",
    "                axes_recon[0, col_idx].imshow(orig_img.squeeze(), cmap='gray')\n",
    "            else:  # RGB\n",
    "                axes_recon[0, col_idx].imshow(orig_img.permute(1, 2, 0))\n",
    "            \n",
    "            if sample_idx == 1:  # Middle sample gets the checkpoint name\n",
    "                axes_recon[0, col_idx].set_title(f'{name}\\nOriginal', fontsize=10)\n",
    "            else:\n",
    "                axes_recon[0, col_idx].set_title('Original', fontsize=10)\n",
    "            axes_recon[0, col_idx].axis('off')\n",
    "            \n",
    "            # Reconstructed image\n",
    "            recon_img = reconstructions[sample_idx]\n",
    "            if recon_img.shape[0] == 1:  # Grayscale\n",
    "                axes_recon[1, col_idx].imshow(recon_img.squeeze(), cmap='gray')\n",
    "            else:  # RGB\n",
    "                axes_recon[1, col_idx].imshow(recon_img.permute(1, 2, 0))\n",
    "            \n",
    "            if sample_idx == 1:  # Middle sample gets the checkpoint name\n",
    "                axes_recon[1, col_idx].set_title(f'{name}\\nReconstructed', fontsize=10)\n",
    "            else:\n",
    "                axes_recon[1, col_idx].set_title('Reconstructed', fontsize=10)\n",
    "            axes_recon[1, col_idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{comparison_name} - Reconstruction Comparison (3 samples per checkpoint)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # PCA Analysis\n",
    "    print(f\"\\n=== PCA Analysis for {n_checkpoints} checkpoints ===\")\n",
    "    \n",
    "    fig_pca, axes_pca = plt.subplots(2, n_checkpoints, figsize=(6*n_checkpoints, 12))\n",
    "    if n_checkpoints == 1:\n",
    "        axes_pca = axes_pca.reshape(2, 1)\n",
    "    \n",
    "    for i, (embeddings, labels, attrs, digits, name) in enumerate(zip(all_embeddings, all_labels, all_attrs, all_digits, checkpoint_names)):\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=3)\n",
    "        embeddings_pca = pca.fit_transform(embeddings)\n",
    "        embeddings_2d = embeddings_pca[:, [0, 1]]  # Use PC1 and PC2\n",
    "        # Plot 1: Colored by attributes\n",
    "        unique_attrs = np.unique(attrs)\n",
    "        colors_attrs = plt.cm.Set1(np.linspace(0, 1, len(unique_attrs)))\n",
    "        \n",
    "        for j, attr in enumerate(unique_attrs):\n",
    "            mask = attrs == attr\n",
    "            axes_pca[0, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                 c=[colors_attrs[j]], label=f'Attr {int(attr)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_pca[0, i].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "        axes_pca[0, i].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "        axes_pca[0, i].set_title(f'{name}\\nPCA - Colored by Attribute')\n",
    "        axes_pca[0, i].legend(fontsize=8)\n",
    "        axes_pca[0, i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Colored by digits\n",
    "        unique_digits = np.unique(digits)\n",
    "        colors_digits = plt.cm.tab10(np.linspace(0, 1, len(unique_digits)))\n",
    "        \n",
    "        for j, digit in enumerate(unique_digits):\n",
    "            mask = digits == digit\n",
    "            axes_pca[1, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                 c=[colors_digits[j]], label=f'Digit {int(digit)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_pca[1, i].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%})')\n",
    "        axes_pca[1, i].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%})')\n",
    "        axes_pca[1, i].set_title(f'{name}\\nPCA - Colored by Digit')\n",
    "        axes_pca[1, i].legend(fontsize=8)\n",
    "        axes_pca[1, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'{comparison_name} - PCA Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # UMAP Analysis\n",
    "    print(f\"\\n=== UMAP Analysis for {n_checkpoints} checkpoints ===\")\n",
    "    \n",
    "    fig_umap, axes_umap = plt.subplots(2, n_checkpoints, figsize=(6*n_checkpoints, 12))\n",
    "    if n_checkpoints == 1:\n",
    "        axes_umap = axes_umap.reshape(2, 1)\n",
    "    \n",
    "    for i, (embeddings, labels, attrs, digits, name) in enumerate(zip(all_embeddings, all_labels, all_attrs, all_digits, checkpoint_names)):\n",
    "        # Subsample for UMAP if needed\n",
    "        max_samples = 3000\n",
    "        if len(embeddings) > max_samples:\n",
    "            indices = np.random.choice(len(embeddings), max_samples, replace=False)\n",
    "            embeddings_subset = embeddings[indices]\n",
    "            attrs_subset = attrs[indices]\n",
    "            digits_subset = digits[indices]\n",
    "        else:\n",
    "            embeddings_subset = embeddings\n",
    "            attrs_subset = attrs\n",
    "            digits_subset = digits\n",
    "        \n",
    "        # Apply UMAP\n",
    "        # Use appropriate parameters for UMAP\n",
    "        n_neighbors = min(15, max(2, len(embeddings_subset)//10))\n",
    "        umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=n_neighbors, min_dist=0.1, verbose=False, n_jobs=1)\n",
    "        embeddings_2d = umap_reducer.fit_transform(embeddings_subset)\n",
    "        \n",
    "        # Plot 1: Colored by attributes\n",
    "        unique_attrs = np.unique(attrs_subset)\n",
    "        colors_attrs = plt.cm.Set1(np.linspace(0, 1, len(unique_attrs)))\n",
    "        \n",
    "        for j, attr in enumerate(unique_attrs):\n",
    "            mask = attrs_subset == attr\n",
    "            axes_umap[0, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                  c=[colors_attrs[j]], label=f'Attr {int(attr)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_umap[0, i].set_xlabel('UMAP Dimension 1')\n",
    "        axes_umap[0, i].set_ylabel('UMAP Dimension 2')\n",
    "        axes_umap[0, i].set_title(f'{name}\\nUMAP - Colored by Attribute')\n",
    "        axes_umap[0, i].legend(fontsize=8)\n",
    "        axes_umap[0, i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Colored by digits\n",
    "        unique_digits = np.unique(digits_subset)\n",
    "        colors_digits = plt.cm.tab10(np.linspace(0, 1, len(unique_digits)))\n",
    "        \n",
    "        for j, digit in enumerate(unique_digits):\n",
    "            mask = digits_subset == digit\n",
    "            axes_umap[1, i].scatter(embeddings_2d[mask, 0], embeddings_2d[mask, 1], \n",
    "                                  c=[colors_digits[j]], label=f'Digit {int(digit)}', alpha=0.6, s=15)\n",
    "        \n",
    "        axes_umap[1, i].set_xlabel('UMAP Dimension 1')\n",
    "        axes_umap[1, i].set_ylabel('UMAP Dimension 2')\n",
    "        axes_umap[1, i].set_title(f'{name}\\nUMAP - Colored by Digit')\n",
    "        axes_umap[1, i].legend(fontsize=8)\n",
    "        axes_umap[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f'{comparison_name} - UMAP Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAnalysis complete for {n_checkpoints} checkpoints!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
